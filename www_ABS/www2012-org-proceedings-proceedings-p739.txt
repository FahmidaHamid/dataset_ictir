hierarchical taxonomies provide a multilevel view of large document collections, allowing users to rapidly drill down to  ne-grained distinctions in topics of interest. we show that automatically induced taxonomies can be made more robust by combining text with relational links. the underlying mechanism is a bayesian generative model in which a latent hierarchical structure explains the observed data   thus,  nding hierarchical groups of documents with similar word distributions and dense network connections. as a nonparametric bayesian model, our approach does not require pre-speci cation of the branching factor at each non-terminal, but  nds the appropriate level of detail directly from the data. unlike many prior latent space models of network structure, the complexity of our approach does not grow quadratically in the number of documents, enabling application to networks with more than ten thousand nodes. experimental results on hypertext and citation network corpora demonstrate the advantages of our hierarchical, multimodal approach.
