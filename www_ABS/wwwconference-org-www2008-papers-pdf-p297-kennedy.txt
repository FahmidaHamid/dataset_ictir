can we leverage the community-contributed collections of rich media on the web to automatically generate representative and diverse views of the world s landmarks? we use a combination of context and content-based tools to generate representative sets of images for location-driven features and landmarks, a common search task. to do that, we using location and other metadata, as well as tags associated with images, and the images  visual features. we present an approach to extracting tags that represent landmarks. we show how to use unsupervised methods to extract representative views and images for each landmark. this approach can potentially scale to provide better search and representation for landmarks, worldwide. we evaluate the system in the context of image search using a real-life dataset of 110,000 images from the san francisco area.
