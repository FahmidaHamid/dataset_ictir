SEISA: Set Expansion by Iterative Similarity Aggregation

âˆ—
Yeye He

University of Wisconsin-Madison

Madison, WI 53706

heyeye@cs.wisc.edu

â€ 

Dong Xin

Microsoft Research
Redmond, WA 98052

dongxin@microsoft.com

ABSTRACT
In this paper, we study the problem of expanding a set of given seed
entities into a more complete set by discovering other entities that
also belong to the same concept set. A typical example is to use
â€œCanonâ€ and â€œNikonâ€ as seed entities, and derive other entities
(e.g., â€œOlympusâ€) in the same concept set of camera brands. In
order to discover such relevant entities, we exploit several web data
sources, including lists extracted from web pages and user queries
from a web search engine. While these web data are highly diverse
with rich information that usually cover a wide range of the do-
mains of interest, they tend to be very noisy. We observe that pre-
viously proposed random walk based approaches do not perform
very well on these noisy data sources. Accordingly, we propose a
new general framework based on iterative similarity aggregation,
and present detailed experimental results to show that, when using
general-purpose web data for set expansion, our approach outper-
forms previous techniques in terms of both precision and recall.
Categories and Subject Descriptors: H.2.8 Database Applica-
tion: Data Mining
General Terms: Algorithms.
Keywords: Set Expansion, Named Entity Recognition, Similarity
Measure.

1.

INTRODUCTION

Set expansion refers to the practical problem of expanding a
small set of â€œseedâ€ entities, into a more complete set by discover-
ing other entities that also belong to the same â€œconcept setâ€. Here
a â€œconcept setâ€ can be any collection of entities that conceptually
form a set that people have in mind, and â€œseedsâ€ are the instances of
entities in the set. As an example, a person wanting to discover all
camera brand names may give a small number of well-known brand
names like â€œCanonâ€ and â€œNikonâ€ as seeds, the set expansion
techniques would leverage the given data sources to discover other
camera brands, such as â€œLeicaâ€, â€œPentaxâ€ and â€œOlympusâ€
that are also camera brands.

Set expansion systems are of practical importance and can be
used in various applications. For instance, web search engines may
use the set expansion tools to create a comprehensive entity repos-
itory (for, say, brand names of each product category), in order
âˆ—
Work done at Microsoft Research
â€ 
Work done at Microsoft Research.
(dongxin@google.com).

Now with Google

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2011, March 28â€“April 1, 2011, Hyderabad, India.
ACM 978-1-4503-0632-4/11/03.

to deliver better results to entity-oriented queries. As another ex-
ample, the task of named entity recognition can also leverage the
results generated by set expansion tools [13].

Considerable progresses have been made in developing high-
quality set expansion systems. The most relevant efforts include
Google Sets [1], which employs proprietary algorithms to do set
expansions. However, due to its proprietary nature, algorithms and
data sources behind Google Sets are not publicly available for fu-
ture research endeavors.

Another prominent line of work is the SEAL system [16, 17,
18, 19]. They adopted a two-phase strategy, where they ï¬rst build
customized text wrappers based on the input seeds in order to ex-
tract candidate entities from web pages in a precise manner. They
then use a graph-based random walk to rank candidates entities
based on their closeness to the seeds on the graph. While they have
demonstrated that this customized data extraction/ranking process
can produce results with high quality, the necessary online data ex-
traction can be costly and time-consuming.

Here we study the problem of conducting set expansion using
general web data sources without resorting to online data extrac-
tions speciï¬c to the given seeds. In particular, we look at two com-
mon types of web data: the HTML lists extracted from web pages
by web crawls (henceforth referred to as the Web Lists) and the
web search query logs (the Query Logs). We model both types of
data using bipartite graphs to provide a uniï¬ed computation model.
Such general-purpose web data can be highly useful for set ex-
pansion tasks: they are very diverse in nature, with rich information
that covers most domains of interest. In addition, since these gen-
eral data are not domain/seed speciï¬c, they can be pre-processed
and optimized for efï¬ciency purposes.

However, these general web data can be inherently noisy. Ran-
dom walk or other similarity measures along may not be sufï¬cient
to distinguish true results from the noises, especially when the num-
ber of seeds are limited. As we observe in our experimental evalua-
tions, that random walk based ranking techniques used in previous
work perform poorly on the general-purpose Web Lists or Query
Logs and produce results with low precision/recall. Partly because
of that, previous approaches [16, 17, 18, 19] use seed-speciï¬c and
page-speciï¬c wrappers to reduce the candidate set to a smaller and
much cleaner subset over which the random walk based ranking
techniques work reasonably well. However, we note that this addi-
tional data extraction process is at the cost of overall architectural
complexity and system responsiveness.

Unlike previous approaches, we in this work propose a general
framework that only uses general-purpose web data without resort-
ing to on-line data extractions speciï¬c to the given seeds. In par-
ticular, while previous random walk based approaches leverage the
intuition that candidates close to the given seeds in the graph struc-

WWW 2011 â€“ Session: Information ExtractionMarch 28â€“April 1, 2011, Hyderabad, India427ture are more likely to belong to the same concept set as the seeds;
we take an alternative tack and propose to measure the quality of
an expanded set of entities relative to the given set of seeds in a
more straightforward and comprehensible way.
Intuitively, a set
of expanded results is â€œgoodâ€ if it has two key properties: (1) the
set of produced entities are similar to the given seeds; (2) the set
of produced entities are coherent in the sense that they represent a
consistent concept. We abstract the intuitions and deï¬ne quality of
the result set as the sum of two component scores: the Relevance of
a set of entities that measures their similarity with the given seeds,
and Coherence of the set of entities produced which is how closely
the entities in this set are related to each other. Based on this qual-
ity measure, we further develop a class of iterative set expansion
algorithms for which we call SEISA (Set Expansion by Iterative
Similarity Aggregation). We show that SEISA is robust and effec-
tive in producing expanded sets over noisy web data sources.

The rest of the paper is organized as follows. We summarize the
related work in the space of set expansion in Section 2. We then
formally deï¬ne the problem of set expansion using the new quality
metric we propose in Section 3. In Section 4 we detail our itera-
tive set expansion algorithms. Finally we present our experimental
results in Section 5 and conclude this paper in Section 6.

2. RELATED WORK

There is a signiï¬cant body of related work in the broad space of
information extraction and named entity extraction. We will only
summarize work most relevant to set expansion due the limit of
space.

Wang and Cohen [16, 17, 18, 19] developed the SEAL system
for set expansion, using a two-phase extraction/ranking architec-
ture.
In the ï¬rst extraction phase, they build for each web page
customized wrappers using maximal left/right context that would
enclose all given seeds, which are in turn applied on the web page
from which they are constructed to extract candidate terms in ad-
dition to the given seeds. In the second ranking phase, web pages,
wrappers and candidate terms are modeled as nodes in the graph,
and random walk techniques are used to rank candidates based on
their structural proximity to the seeds in the graph. In compari-
son, our approach ranks a set of candidates as a whole based on
its relevance and coherence, and does not require page-speciï¬c and
seed-speciï¬c data extraction process.

Agichtein et al. [4] introduce the Snowball system that bootstraps
from a small number of input tuples, by ï¬rst obtaining typical con-
textual patterns of the seed tuples from the web pages, which are
used in turn to extract more tuples. While Snowball is well suited
for extracting certain types of structured data like binary relations,
it may not work well for set expansion due to its reliance on textual
context patterns (sets can be viewed as unary relations of tuples,
whose context can be much more dynamic and less predictable than
that of binary relations).

Etzioni et al. [6, 7] develop the KnowItAll system that automat-
ically extracts facts from the web using textual patterns like â€œcities
such as Paris, London and New Yorkâ€ to extract candidate entities.
Candidates are then ranked in a bootstrapping manner using statis-
tical information gathered from the search engine such as PMI over
hit counts.

Talukdar et al. [14] study the problem of set expansion from open
text. They propose to automatically identify trigger-words which
indicate patterns in a bootstrapping manner.

Ghahramani et al. [8] uses Bayesian inference to solve the prob-
lem of set expansion. It has been shown in [18] that this candidate
ranking mechanism is comparable to random walk in quality of the
results of the expanded set.

Canon

Nikon

Leica

VW

BMW

List01

List02

List03

List04

List05

Canon

Nikon

Leica

VW

BMW

camera

japan

laptop

dealer

mpg

(a) Web List Data

(b) Query Log Data

Figure 1: Bipartite graph data model

Set expansion is also somewhat related to the problem of class
label acquisition [15, 20] where the goal is to propage a set of class
labels to data instances using labeled traning examples. While the
set expansion problem can be modeled as propagating class labels
associated with seeds to candidate entities, we observe that a large
number of training examples is necessary in order for these tech-
niques to be effective.

Finally Google Sets [1] does set expansions using propriety al-

gorithms which are not publicly available.

3. PROBLEM DEFINITION
3.1 Data Model

In this work we target general web data sources. Speciï¬cally,
we look at lists extracted from the HTML web pages (the Web List
data), and the web search query logs (the Query Log data). In each
case, we model the data as bipartite graphs as in Figure 1, with
candidate terms being nodes on one side (henceforth referred to as
term-nodes) and their contexts on the other side. Since we use tex-
tual terms in the web data as candidate entities for the expanded set,
from this point on we will be using the word â€œtermâ€ interchange-
ably with â€œentityâ€.

Web List Data. For Web List as in Figure 1a, each unique web
list crawled from the web, (â€œList01â€, â€œList02â€, etc), is mod-
eled as a node on the right-hand-side, while each term that appears
in those web lists is modeled as a term-node on the left hand side.
In this example, the underlined nodes â€œCanonâ€ and â€œNikonâ€ on
the left are the seed terms, while the remaining terms, including
â€œLeicaâ€, â€œVWâ€ and â€œBMWâ€, are possible candidate terms. There
is an edge connecting a term-node with a list-node if that term is a
members of the list. For example, the list-node List01 connects
to â€œCanonâ€, â€œNikonâ€ and â€œLeicaâ€, indicating that all three
terms are members of List01, which is probably a web list on
some web page that enumerates a list of camera brands.

While it is possible to resort to additional information of the web
data to assign different weights to each edge (using the quality of
the page from which the list is extracted, for example), we in this
work adopt a simpler approach that only assigns a uniform weight
of 1 to each edge in the Web List graph. We in our experiments ï¬nd
this approach to work quite well.

Query Log Data. Query log data is modeled as in Figure 1b.
Here for each keyword query, we break up the query into two parts,
the term and the context. The context is a preï¬x or sufï¬x of the
query up to 2 tokens, and the term is the remainder of the query.
Each term is again modeled as a graph node on the left, the context
is modeled as a node on the right.

There are various ways in which we can model edges in the graph
for query log data. In this work we assign weight of the edge be-

WWW 2011 â€“ Session: Information ExtractionMarch 28â€“April 1, 2011, Hyderabad, India428tween each pair of nodes using the Mutual Information between the
query term and query context, which is deï¬ned in Deï¬nition 1.

DEFINITION 1. Let ğ‘ƒ ğ‘Ÿğ‘œğ‘(ğ‘¡) be the probability that term ğ‘¡ oc-
cur in the query log, ğ‘ƒ ğ‘Ÿğ‘œğ‘(ğ‘) be the probability that context ğ‘ oc-
cur in the query log, let ğ‘ƒ ğ‘Ÿğ‘œğ‘(ğ‘¡, ğ‘) be the probability that the term
ğ‘¡ and context ğ‘ co-occur in the query log. The Mutual Information
H(t, c) is deï¬ned as: ğ»(ğ‘¡, ğ‘) =

ğ‘ƒ ğ‘Ÿğ‘œğ‘(ğ‘¡)âˆ—ğ‘ƒ ğ‘Ÿğ‘œğ‘(ğ‘)

ğ‘ƒ ğ‘Ÿğ‘œğ‘(ğ‘¡,ğ‘)

Furthermore, we only keep the edge between a pair of nodes
if the Mutual Information between the term and the context (or the
weight on the edge) is positive, and additionally, the co-occurrences
of the term and the context is frequent enough to be above certain
threshold. Figure 1b is an example of the resulting bipartite graph
after this simple processing.

In general, we feel that this bipartite graph model is straightfor-
ward and general enough to be applied and extended to other types
of data sources.
3.2 Similarity Metric

With this bipartite data model, intuitively the overall task of do-
ing set expansion given a set of seeds can to an extent be viewed
as the problem of ï¬nding term-nodes that are similar to the given
seed-nodes, using the right hand side nodes as the features. In order
to measure similarities between the term-nodes, common similarity
metrics, like Jaccard Similarity [11] and Cosine Similarity [11] as
deï¬ned below, can all be used.

DEFINITION 2. [11] Let ğ‘¥, ğ‘¦ be two term-nodes on the left hand
side. Let ğ¿ğ‘¥ and ğ¿ğ‘¦ be the two sets of right side nodes that connect
to node ğ‘¥ and ğ‘¦, respectively. The Jaccard Similarity of ğ‘¥ and ğ‘¦,
âˆ£ğ¿ğ‘¥âˆ©ğ¿ğ‘¦âˆ£
denoted as ğ‘†ğ‘–ğ‘šğ½ğ‘ğ‘(ğ‘¥, ğ‘¦), is deï¬ned as ğ‘†ğ‘–ğ‘šğ½ğ‘ğ‘(ğ‘¥, ğ‘¦) =
âˆ£ğ¿ğ‘¥âˆªğ¿ğ‘¦âˆ£ .
DEFINITION 3. [11] Let ğ‘¥, ğ‘¦ be two term-nodes on the left hand
side. Let ğ‘‰ğ‘¥ and ğ‘‰ğ‘¦ be the weight vectors that indicate the weights
of the edges that connect web lists to node ğ‘¥ and ğ‘¦, respectively.
The Cosine Similarity of ğ‘¥ and ğ‘¦, denoted as ğ‘†ğ‘–ğ‘šğ¶ğ‘œğ‘ (ğ‘¥, ğ‘¦), is
deï¬ned as ğ‘†ğ‘–ğ‘šğ¶ğ‘œğ‘ (ğ‘¥, ğ‘¦) = ğ‘‰ğ‘¥â‹…ğ‘‰ğ‘¦

âˆ¥ğ‘‰ğ‘¥âˆ¥âˆ¥ğ‘‰ğ‘¦âˆ¥ .

We use the following two examples as simple illustrations of the

Jaccard similarity and Cosine similarity.

EXAMPLE 1. We ï¬rst illustrate the computation of Jaccard sim-
ilarity of two term-nodes in our bipartite graph model.
In Fig-
ure 1a, the term-node â€œCanonâ€ connects to list nodes ğ¿â€œğ¶ğ‘ğ‘›ğ‘œğ‘›â€²â€²
= {â€œList01â€, â€œList02â€}; while the term-node â€œLeicaâ€ con-
nects to nodes ğ¿â€œğ¿ğ‘’ğ‘–ğ‘ğ‘â€²â€² = {â€œList01â€, â€œList02â€, â€œList03â€,
â€œList04â€}. By Deï¬nition 2, the Jaccard similarity between the
âˆ£ğ¿â€œğ¶ğ‘ğ‘›ğ‘œğ‘›â€²â€²âˆ©ğ¿â€œğ¿ğ‘’ğ‘–ğ‘ğ‘â€²â€²âˆ£
seed-nodes â€œLeicaâ€ and â€œCanonâ€ is
âˆ£ğ¿â€œğ¶ğ‘ğ‘›ğ‘œğ‘›â€²â€²âˆªğ¿â€œğ¿ğ‘’ğ‘–ğ‘ğ‘â€²â€²âˆ£ =
2
= 0.5. Similarly, the similarity between â€œLeicaâ€ and the other
4
seed-node â€œNikonâ€ is also 2
4

On the other hand, the Jaccard similarities between â€œVWâ€ and
both of the seed-nodes â€œCanonâ€ and â€œNikonâ€ are 0
= 0. There-
6
fore, using the Jaccard Similarity deï¬nition, the term â€œLeicaâ€ is
more similar to both seeds than the term â€œVMâ€.

= 0.5.

Next we show how Cosine similarity between term-nodes is com-
puted. In Figure 1a, the term-node â€œCanonâ€ connects to ğ¿â€œğ¶ğ‘ğ‘›ğ‘œğ‘›â€²â€²
={â€œList01â€, â€œList02â€}, its edge weight vector ğ‘‰â€œCanonâ€ is
thus (1, 1, 0, 0, 0). By the same token, the edge weight vector for
â€œLeicaâ€ is ğ‘‰â€œLeicaâ€ = (1, 1, 1, 1, 0). According to Deï¬nition 2,
the Cosine similarity between nodes â€œLeicaâ€ and â€œCanonâ€ is
ğ‘‰â€œğ¶ğ‘ğ‘›ğ‘œğ‘›â€²â€²â‹…ğ‘‰â€œğ¿ğ‘’ğ‘–ğ‘ğ‘â€²â€²
âˆ¥ğ‘‰â€œğ¶ğ‘ğ‘›ğ‘œğ‘›â€²â€²âˆ¥âˆ¥ğ‘‰â€œğ¿ğ‘’ğ‘–ğ‘ğ‘â€²â€²âˆ¥ = 2
= 0.71. Similarly, the similar-
ity between â€œLeicaâ€ and the other seed-node â€œNikonâ€ is also
2.83

= 0.71.

2.83

2

(a) A set with high relevance

(b) A set with high coherence

Figure 2: Quality of an expanded set

The Cosine similarities between â€œVWâ€ and both of the seed-
nodes â€œCanonâ€ and â€œNikonâ€ are 0 due to the lack of overlap
in the right side list-nodes. We again have the term â€œLeicaâ€ to
be more similar to seeds than the term â€œVMâ€.

While in this section we only discuss two most commonly used
similarity metrics, the Jaccard Similarity and the Cosine Similarity,
we emphasize that the set expansion framework to be introduce in
detail in Section 4 is general and extensible enough that any other
similarity metrics can be easily plugged in to be used. Furthermore,
in our experimental evaluations, we ï¬nd that the performances of
set expansion using both similarity metrics are reasonably good,
underlining the generality of the framework we propose.
3.3 Quality Measurement

While the previous work uses techniques like random walk to
rank individual terms based on their graph structure similarity to
the given seeds, we see the expanded set of entities as a whole and
propose a simple and intuitive metric to measure the quality of the
expanded set, as will be detailed in this section.

The ï¬rst observation we have is that, the more similar the ex-
panded entities are to the given seed entities, the better quality the
expanded set. This is intuitive because after all the task of set ex-
pansion is to ï¬nd entities that are in the same â€œconcept setâ€ as the
seeds, which by deï¬nition should be somewhat similar to the seeds.
We formalize this observation with the following deï¬nition of rel-
evance to capture the similarity between the expanded set and the
seed set.

DEFINITION 4. Let ğ‘ˆ be the universe of entities, ğ‘… âŠ† ğ‘ˆ be
the expanded set, and ğ‘† âŠ† ğ‘ˆ be the seed set. Let ğ‘†ğ‘–ğ‘š : ğ‘ˆ Ã—
ğ‘ˆ â†’ [0, 1] be the function that measures the similarity of any two
entities. The relevance of ğ‘… with respect to ğ‘† is deï¬ned as:

ğ‘†ğ‘Ÿğ‘’ğ‘™(ğ‘…, ğ‘†) =

1

âˆ£ğ‘…âˆ£ âˆ— âˆ£ğ‘†âˆ£ âˆ— âˆ‘

ğ‘Ÿâˆˆğ‘…

âˆ‘

ğ‘ âˆˆğ‘†

ğ‘†ğ‘–ğ‘š(ğ‘ , ğ‘Ÿ)

To better illustrate this deï¬nition of relevance, we use Figure 2
to graphically demonstrate the quality of the expanded set. In both
Figure 2a and Figure 2b, the two solid dots in the middle represent
the given seed set ğ‘†, while the circles surrounding these two dots
are the derived entities that constitute the expanded set ğ‘…. The
similarity of any two entities is then represented as the distance of
these two dots in the graph.

It is clear that in both of these two ï¬gures, the expanded set of
entities as circled by the dashed oval are very similar (or graphi-
cally speaking, close) to the two given seeds. So in terms of our
relevance metric, both of the two sets in Figure 2a and Figure 2b
have high relevance to the given seeds.

However, we observe that this deï¬nition of relevance alone does
not fully capture the quality of the expanded set. The reason for

WWW 2011 â€“ Session: Information ExtractionMarch 28â€“April 1, 2011, Hyderabad, India429this is that while the overarching goal of set expansion is to ï¬nd
a consistent â€œconcept setâ€ that are very similar to the given seeds,
there could be cases where a set of entities are similar to the seeds
but not consistent enough to be a coherent concept set. As an ex-
ample, in Figure 2a, while the expanded entities as denoted by the
circles are close to the given seeds, they are relative dispersed in
the space and may not form a consistent â€œconcept setâ€ as required
by set expansion. On the other hand, the the expanded entities in
Figure 2b are not only equally close to the given seeds as in Fig-
ure 2a, they are also much closer to each other to form a consistent
â€œconcept setâ€. Thus, the expanded entities in Figure 2b may be a
better candidate for the expanded set than the entities in Figure 2a.
To capture the intuition in Figure 2b that the closer the entities in
the expanded set are to each other, the more coherent and thus better
the set as a whole is, we formally deï¬ne the notion of coherence in
the following.

DEFINITION 5. Let ğ‘ˆ be the universe of entities, ğ‘… âŠ† ğ‘ˆ be the
expanded set, ğ‘†ğ‘–ğ‘š : ğ‘ˆ Ã— ğ‘ˆ â†’ [0, 1] be the function that measures
the similarity of any two entities. The coherence of ğ‘… is deï¬ned as:

1

âˆ£ğ‘…âˆ£ â‹… âˆ£ğ‘…âˆ£ âˆ—

âˆ£ğ‘…âˆ£âˆ‘

âˆ£ğ‘…âˆ£âˆ‘

ğ‘–=1

ğ‘—>ğ‘–

ğ‘†ğ‘–ğ‘š(ğ‘Ÿğ‘–, ğ‘Ÿğ‘—)

ğ‘†ğ‘ğ‘œâ„(ğ‘…) =

where ğ‘Ÿğ‘–, ğ‘Ÿğ‘— âˆˆ ğ‘….

Based on the observation that both relevance and coherence con-
tribute to the quality of an expanded set, we deï¬ne the quality of
the expanded set as the weighted sum of relevance and coherence
as follows.

DEFINITION 6. Let ğ‘ˆ be the universe of entities, Let ğ‘… âŠ† ğ‘ˆ
be the expanded set, ğ‘† âŠ† ğ‘ˆ be the seed set. Let 0 â‰¤ ğ›¼ â‰¤ 1 be
the constant weight factor. The quality of the expanded set ğ‘… with
respect to the seed set ğ‘†, ğ‘„(ğ‘…, ğ‘†), is deï¬ned as:

ğ‘„(ğ‘…, ğ‘†) = ğ›¼ âˆ— ğ‘†ğ‘Ÿğ‘’ğ‘™(ğ‘…, ğ‘†) + (1âˆ’ ğ›¼) âˆ— ğ‘†ğ‘ğ‘œâ„(ğ‘…)

Here, ğ›¼ is a constant weight that balances the emphasis between
relevance and coherence. In our experiments that we will detail in
Section 5, we ï¬nd ğ›¼ = 0.5 to be a good value in practice, and this
intuitive yet simple deï¬nition of quality works well in the extensive
experiments that are conducted.
3.4 Problem Statement

With the deï¬nition of quality metric, we formally state the prob-
lem as follows. Given the universe of candidate terms ğ‘ˆ and some
seeds ğ‘† âŠ† ğ‘ˆ; given a similarity function ğ‘†ğ‘–ğ‘š : ğ‘ˆ Ã— ğ‘ˆ â†’
[0, 1] that measures the similarity of any two terms, identify the
expanded seed set ğ‘…, ğ‘… âŠ† ğ‘ˆ and is of size ğ¾, such that the objec-
tive function ğ‘„(ğ‘…, ğ‘†) is maximized, where

ğ‘„(ğ‘…, ğ‘†) = ğ›¼ âˆ— ğ‘†ğ‘Ÿğ‘’ğ‘™(ğ‘…, ğ‘†) + (1âˆ’ ğ›¼) âˆ— ğ‘†ğ‘ğ‘œâ„(ğ‘…)

Intuitively, the expanded seed set, or the ESS, is the core com-
ponent of the concept set that we want to expand, and consists of
entities that we know with high conï¬dence that belong to the de-
sired concept set. We say an ESS is good if its quality score is high.
Once a good ESS (denoted as ğ‘…) is derived, individual terms ğ‘¡ can
then be ranked based on ğ‘… and the seed set ğ‘† using the ranking
function ğ‘”(ğ‘¡, ğ‘…, ğ‘†), which is again a straightforward combination
of relevance score and coherence score as follows.
âˆ£ğ‘…âˆ£âˆ‘

âˆ£ğ‘†âˆ£âˆ‘

ğ‘”(ğ‘¡, ğ‘…, ğ‘†) =

ğ‘†ğ‘–ğ‘š(ğ‘¡, ğ‘ ğ‘–) +

ğ‘†ğ‘–ğ‘š(ğ‘¡, ğ‘Ÿğ‘–) (1)

ğ›¼
âˆ£ğ‘†âˆ£

ğ‘–=1

(1 âˆ’ ğ›¼)

âˆ£ğ‘…âˆ£

ğ‘–=1

where ğ‘Ÿğ‘– âˆˆ ğ‘… and ğ‘ ğ‘– âˆˆ ğ‘†.

However, we show that the problem of ï¬nding the optimal ğ‘… of

size ğ¾ with maximum quality score is NP-hard.

THEOREM 1. Given the seed set ğ‘†, the problem of ï¬nding an
entity set ğ‘… of size ğ¾ that maximizes the objective function ğ‘„(ğ‘…, ğ‘†)
is NP-Hard.

The hardness of this problem can be proved by reduction from
the maximum clique problem [9]. Details of the proof can be found
in Appendix 8.1.

4. ALGORITHMS FOR SET EXPANSION

Given Theorem 1 which states that it is NP-Hard to ï¬nd the
optimal expanded seed set (ESS), we in this section propose two
greedy algorithms, the static thresholding algorithm and the dy-
namic thresholding algorithm, that iteratively reï¬ne a candidate
ESS ğ‘… of size ğ¾ to maximize ğ‘„(ğ‘…, ğ‘†) (Deï¬nition 6). Both al-
gorithms are built on top of an automatic score thresholding tech-
nique. In this section, we ï¬rst outline two algorithms, then describe
the automatic score thresholding method, and ï¬nally, we discuss
the connection of our proposed algorithms and the standard ran-
dom walk based approaches.
4.1

Iterative Similarity Aggregation

On the high level, the static thresholding algorithm ï¬xes the size
of ESS ğ‘… at the beginning, and then iteratively searches for terms in
ğ‘… to maximize ğ‘„(ğ‘…, ğ‘†); while the dynamic thresholding algorithm
reï¬nes both the size of ğ‘… and contents of ğ‘… at the same time in each
iteration.
4.1.1
The static thresholding algorithm starts with a good guess of
ESS, then iteratively improve the quality metric as deï¬ned in Deï¬-
nition 6 by replacing one entity in the ESS of the previous iteration,
until the computation of ESS converges and a local maximum of
the quality score is reached. The pseudo-code of the algorithm is
described in Algorithm 1.

Static Thresholding Algorithm

The static thresholding algorithm takes two parameters, the set
of seed entities, ğ‘ ğ‘’ğ‘’ğ‘‘ğ‘ , and the ğ‘”ğ‘Ÿğ‘ğ‘â„ with all candidate ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘  as
left side nodes. We start by computing the relevance score of each
term with the seeds ğ‘†ğ‘Ÿğ‘’ğ‘™(ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–, ğ‘ ğ‘’ğ‘’ğ‘‘ğ‘ ), as deï¬ned in Deï¬nition 4,
in the ï¬rst for loop. We then rank the terms according to their rel-
evance scores, and pick top ğ¾ ranked terms as the initial estimate
of the ESS, ğ‘…0, where the threshold value ğ¾ is determined by a
thresholding analysis of the score distribution that will be detailed
in Section 4.2.

In the subsequent iterations in the while loop, we iteratively com-
pute the new candidate ESS ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿ based on ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿâˆ’1 of the previous
iteration and progressively improve the overall quality score of the
ESS until a local maximum is reached. Speciï¬cally, in each itera-
tion ğ‘–ğ‘¡ğ‘’ğ‘Ÿ, we compute the relevance score of each candidate term
ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘– with the previous ESS ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿâˆ’1, ğ‘†ğ‘Ÿğ‘’ğ‘™(ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–, ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿâˆ’1), and
the corresponding ranking function ğ‘”(ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–) which is a weighted
combination of the relevance score with the ğ‘ ğ‘’ğ‘’ğ‘‘ğ‘ , and the rele-
vance score with ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿâˆ’1. We then sort the candidate terms by
ğ‘–ğ‘¡ğ‘’ğ‘Ÿ âˆ•= ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿâˆ’1,
ğ‘”(ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–). Let the top ranked ğ¾ terms be ğ‘…â€²
we replace the lowest ranked term in ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿâˆ’1 with the top ranked
term ğ‘Ÿ âˆˆ ğ‘…â€²
ğ‘–ğ‘¡ğ‘’ğ‘Ÿ that is not in ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿâˆ’1, and continue the iteration;
otherwise we have converged and will stop and return ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿâˆ’1 as
the result of ESS.

ğ‘–ğ‘¡ğ‘’ğ‘Ÿ, if ğ‘…â€²

We use the following running example to demonstrate how the
static thresholding algorithm works to compute ESS, which can
then be used to rank candidate terms for set expansion.

WWW 2011 â€“ Session: Information ExtractionMarch 28â€“April 1, 2011, Hyderabad, India430Algorithm 1 Static Thresholding Algorithm

Static_Thresholding (ğ‘ ğ‘’ğ‘’ğ‘‘ğ‘ , ğ‘”ğ‘Ÿğ‘ğ‘â„)
for each ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘– in ğ‘”ğ‘Ÿğ‘ğ‘â„.ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘  do

ğ‘…ğ‘’ğ‘™_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[ğ‘–] â† ğ‘†ğ‘Ÿğ‘’ğ‘™(ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–, ğ‘ ğ‘’ğ‘’ğ‘‘ğ‘ )

end for
sort ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘– by ğ‘…ğ‘’ğ‘™_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[ğ‘–] desc
ğ¾ â† Pick_Threshold(ğ‘…ğ‘’ğ‘™_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[ğ‘–])
ğ‘…0 â† the top ğ¾ ranked terms by ğ‘…ğ‘’ğ‘™_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[ğ‘–]
ğ‘–ğ‘¡ğ‘’ğ‘Ÿ â† 1
while true do

for each ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘– in ğ‘”ğ‘Ÿğ‘ğ‘â„.ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘  do

ğ‘†ğ‘–ğ‘š_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[ğ‘–] â† ğ‘†ğ‘Ÿğ‘’ğ‘™(ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–, ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿâˆ’1)
ğ‘”(ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–) â† ğ›¼ âˆ— ğ‘…ğ‘’ğ‘™_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[ğ‘–] + (1 âˆ’ ğ›¼) âˆ— ğ‘†ğ‘–ğ‘š_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[ğ‘–]

end for
sort ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘– by ğ‘”(ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–) desc
ğ‘–ğ‘¡ğ‘’ğ‘Ÿ â† the top ğ¾ terms by ğ‘”(ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–)
ğ‘…â€²
ğ‘–ğ‘¡ğ‘’ğ‘Ÿ âˆ•= ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿâˆ’1 then
if ğ‘…â€²
let ğ‘Ÿ âˆˆ ğ‘…â€²
let ğ‘ âˆˆ ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿ be the last ranked term in ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿâˆ’1
ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿ â† (ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿâˆ’1 âˆª {ğ‘Ÿ}) âˆ’ {ğ‘}
ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿ â† ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿâˆ’1
break

ğ‘–ğ‘¡ğ‘’ğ‘Ÿ be the top ranked term not in ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿâˆ’1

else

end if
ğ‘–ğ‘¡ğ‘’ğ‘Ÿ + +

end while
return ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿ

ğ‘€ =

EXAMPLE 2. Let ğ‘ˆ = {ğ´, ğµ, ğ¶, ğ·, ğ¸, ğ¹} be the set of 6
terms that we consider in this example, in which ğ‘† = {ğ´, ğµ} is
the input seed set. Let the pair-wise similarity matrix ğ‘€ be

(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)

A
B
C
D
E
F

(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)

ğ¹
ğ´ ğµ ğ¶ ğ· ğ¸
0.5 0.8 0.7 0.6 0.7
1
0.6 0.7 0.7 0.5
0.5
1
0
0.8 0.6
1
0.9 0.3
0.8 0.5
0.7 0.7
1
0
0.4
0.6 0.7 0.9 0.8
1
0.3 0.5 0.3 0.5 0.4
1

(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)

where each entry stands for the similarity score of the two corre-
sponding nodes using some similarity metric ğ‘†ğ‘–ğ‘š : ğ‘ˆ Ã— ğ‘ˆ â†’
[0, 1].
For each term ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘– âˆˆ ğ‘ˆ, we ï¬rst compute its relevance score
with the seed set, ğ‘†ğ‘Ÿğ‘’ğ‘™(ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–, ğ‘†). For example, ğ‘†ğ‘Ÿğ‘’ğ‘™(ğ´, ğ‘†) =
(ğ‘€ (ğ´, ğ´) +ğ‘€ (ğ´, ğµ)) = 0.75, ğ‘†ğ‘Ÿğ‘’ğ‘™(ğµ, ğ‘†) = 1
1
(ğ‘€ (ğµ, ğµ) +
2
2
ğ‘€ (ğµ, ğ´)) = 0.75, etc. This gives rise to the ğ‘…ğ‘’ğ‘™_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[] =
{0.75, 0.75, 0.7, 0, 7, 0.65, 0.6}.

Next we invoke the thresholding algorithm (to be detailed in Sec-
tion 4.2), which analyzes the score distribution to ï¬nd a natural
threshold point that separates the high scoring entities from the re-
maining background entities. We use the number of entities above
the threshold as the estimate of the size of ESS. In this particular
case, suppose the thresholding algorithm returns ğ¾ = 4, which
gives us ğ‘…0 = {ğ´, ğµ, ğ¶, ğ·}.
In the ï¬rst iteration (ğ‘–ğ‘¡ğ‘’ğ‘Ÿ = 1), we compute for each term ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘– âˆˆ
ğ‘ˆ its similarity score with the previous estimate of ESS, ğ‘…0, to de-
rive ğ‘†ğ‘Ÿğ‘’ğ‘™(ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–, ğ‘…0). For example, ğ‘†ğ‘Ÿğ‘’ğ‘™(ğ´, ğ‘…0) = 1
(ğ‘€ (ğ´, ğ´)+
4
ğ‘€ (ğ´, ğµ) + ğ‘€ (ğ´, ğ¶) + ğ‘€ (ğ´, ğ·)) = 0.75, while ğ‘†ğ‘Ÿğ‘’ğ‘™(ğµ, ğ‘…0) =
1
(ğ‘€ (ğµ, ğ´) + ğ‘€ (ğµ, ğµ) + ğ‘€ (ğµ, ğ¶) + ğ‘€ (ğµ, ğ·)) = 0.7, so on
and so forth. This leads to ğ‘†ğ‘–ğ‘š_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[] = {0.75, 0.7, 0.6, 0.6,
4
0.75, 0.5}.

Given the weight constant ğ›¼ = 0.5 as used in the quality metric,
âˆ— ğ‘…ğ‘’ğ‘™_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[] =

âˆ— ğ‘†ğ‘–ğ‘š_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[] + 1

the ranking scores ğ‘”[] = 1
2

2

{0.75, 0.725, 0.65, 0.65, 0.7, 0.55}. Sorting the terms in ğ‘ˆ again,
1 = {ğ´, ğµ,
we get a different ordering (ğ´, ğµ, ğ¸, ğ¶, ğ·, ğ¹ ). Let ğ‘…â€²
ğ¸, ğ¶} be the top ranked ğ¾ = 4 terms in the new ordering. Given
1 âˆ•= ğ‘…0, ğ· is the last ranked term in ğ‘…0, and ğ¸ the top
that ğ‘…â€²
1 but not in ğ‘…0, we get ğ‘…1 = ğ‘…0âˆ’{ğ·} +{ğ¸} =
ranked term in ğ‘…â€²
{ğ´, ğµ, ğ¶, ğ¸}.
In the second iteration (ğ‘–ğ‘¡ğ‘’ğ‘Ÿ = 2), we re-compute the simi-
larity score ğ‘†ğ‘–ğ‘š_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[] = {0.725, 0.7, 0.825, 0.55, 0.8, 0.375}.
Combining that with ğ‘…ğ‘’ğ‘™_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[] = {0.75, 0.75, 0.7, 0.7, 0.65,
0.6} we have the new ranking scores ğ‘”[] = {0.7375, 0.725, 0.7625,
0.625, 0.725, 0.4875}. The new top ranked ğ¾ = 4 terms in ğ‘ˆ is
2 = {ğ¶, ğ´, ğµ, ğ¸}. Observe that ğ‘…â€²
ğ‘…â€²
2 == ğ‘…1, we can now stop
the iteration and use the ranking scores ğ‘”[] to generate a ranked
list of terms, (ğ¶, ğ´, ğµ, ğ¸, ğ·, ğ¹ ).

THEOREM 2. The computation of ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿ in Algorithm 1 is guar-
anteed to converge, thus the while loop in Algorithm 1 is bound to
terminate.

Theorem 2 states the nice property that after a ï¬xed number of
iterations, the computation of ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿ will converge and stops chang-
ing for subsequent iterations. Here to outline the intuition of the
proof of the convergence of our algorithm, we note that in our com-
putation of ESS, we are implicitly maximizing the quality score
of ESS. We show that this quality function will monotonically in-
crease in each iteration, until reaching a local maximum, at which
point it will converge and stop. Details of the proof can be found in
Appendix 8.2.

While the algorithm is bound to converge, we donâ€™t have an up-
per bound on the number of iterations it may take before it stops.
However in our experiments, we observe that it converges quickly
and typically takes only a small number of iterations (less than 10).
The reason we term this algorithm static thresholding is due to
the way the estimated size of ESS, ğ¾, is determined. In this static
thresholding algorithm, once threshold ğ¾ is computed in the ï¬rst
iteration, it will stay the same in subsequent iterations. In the fol-
lowing section, we will present a different variant of the algorithm
in which ğ¾ changes from iteration to iteration.
4.1.2 Dynamic Thresholding Algorithm
While the static thresholding algorithm described in Section 4.1.1
is proven to converge, its use of the static threshold (the parameter
ğ¾ in Algorithm 1) as computed in the ï¬rst iteration may not accu-
rately reï¬‚ect the actual size of the ESS. It can be the case that in
subsequent iterations with iterative score computation it becomes
clear that based on the new score distribution, the new threshold
value â€“ which is interpreted as the size of the ESS â€“ is signiï¬cantly
different from the initial estimate derived from the score distribu-
tion for the ï¬rst iteration. To overcome this issue, we in this sec-
tion propose a dynamic thresholding algorithm that iteratively use
the new threshold value of the current score distribution to adjusts
the estimated size of ESS. The algorithm is described in detail in
Algorithm 2.

The structure of this algorithm is similar to Algorithm 1. We ï¬rst
compute the relevance score between each candidate term ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–
and the seeds. We then again invoke the thresholding procedure to
ï¬nd a good threshold value ğ¾0, and use the top ranked ğ¾0 terms
as the initial ESS, ğ‘…0.

In each subsequent iteration, we again rank each term ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–,
using the ranking function ğ‘”(ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–). Based on the new score dis-
tribution computed using ğ‘”(ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–), we re-invoke the automatic
thresholding procedure to determine a new estimate of size of ESS,
ğ¾ğ‘–ğ‘¡ğ‘’ğ‘Ÿ. Observe that instead of using the initial threshold ğ¾0 com-
puted in the ï¬rst iteration as in the static thresholding algorithm,

WWW 2011 â€“ Session: Information ExtractionMarch 28â€“April 1, 2011, Hyderabad, India431Algorithm 2 Dynamic Thresholding Algorithm

Dynamic_Thresholding (ğ‘ ğ‘’ğ‘’ğ‘‘ğ‘ , ğ‘”ğ‘Ÿğ‘ğ‘â„)
for each ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘– in ğ‘”ğ‘Ÿğ‘ğ‘â„.ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘  do
ğ‘…ğ‘’ğ‘™_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[ğ‘–] â† ğ‘†ğ‘Ÿğ‘’ğ‘™(ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–, ğ‘ ğ‘’ğ‘’ğ‘‘ğ‘ )
end for
ğ¾0 â† Pick_Threshold(ğ‘…ğ‘’ğ‘™_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[ğ‘–])
sort ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘– by ğ‘…ğ‘’ğ‘™_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[ğ‘–] desc
ğ‘…0 â† the top ranked ğ¾0 terms by ğ‘…ğ‘’ğ‘™_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[ğ‘–]
ğ‘–ğ‘¡ğ‘’ğ‘Ÿ â† 1
while ğ‘–ğ‘¡ğ‘’ğ‘Ÿ â‰¤ MAX_ITER do

for each ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘– in ğ‘”ğ‘Ÿğ‘ğ‘â„.ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘  do

ğ‘†ğ‘–ğ‘š_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[ğ‘–] â† ğ‘†ğ‘Ÿğ‘’ğ‘™(ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–, ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿâˆ’1)
ğ‘”(ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–) â† ğ›¼ âˆ— ğ‘†ğ‘–ğ‘š_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[ğ‘–] + (1 âˆ’ ğ›¼) âˆ— ğ‘…ğ‘’ğ‘™_ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’[ğ‘–]

end for
ğ¾ğ‘–ğ‘¡ğ‘’ğ‘Ÿ â† Pick_Threshold(ğ‘”(ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–))
sort ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘– by ğ‘”(ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–) desc
ğ‘– â† the top ranked ğ¾ğ‘–ğ‘¡ğ‘’ğ‘Ÿ terms by ğ‘”(ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–)
ğ‘…â€²
ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿ â† ğ‘…â€²
ğ‘–ğ‘¡ğ‘’ğ‘Ÿ + +

ğ‘–ğ‘¡ğ‘’ğ‘Ÿ

end while
return ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿ

Prob.

Figure 4: Automatic thresholding to segment images

image on the left has a hand in the foreground and a dark back-
ground. The task of image segmentation is to separate the fore-
ground hand from the background to get the image on the right
hand side. Each pixel in the image has a gray scale value that again
is assumed to follow two distributions: those belong to the fore-
ground and those belong to the background.

In the computer graphics literature, a number of thresholding al-
gorithms have been proposed and shown to be effective, including
the Iterative Threshold Selection [12] and Otsuâ€™s thresholding [10].
We in this work adopt the Otsuâ€™s thresholding to ï¬nd the good
threshold point that naturally separates those high scoring terms
from those background terms. Formally, Otsuâ€™s threshold is de-
ï¬ned as follows.

DEFINITION 7. Let ğœ”1, ğœ”2 be the probabilities of the two classes
separated by a threshold ğ‘¡, and ğœ2
2 be the variances of these
two classes. The weighted sum of the variances of the two classes
2(ğ‘¡). The Otsuâ€™s thresh-
is ğ‘“ (ğ‘¡) = ğœ2
old ğ‘‡ is deï¬ned as the one that minimizes ğ‘“ (ğ‘¡), or equivalently,
ğ‘‡ = arg min

ğ‘¤(ğ‘¡) = ğœ”1(ğ‘¡)ğœ2

1(ğ‘¡) +ğœ” 2(ğ‘¡)ğœ2

1, ğœ2

(ğ‘“ (ğ‘¥)).

Score

ğ‘¥

Figure 3: Thresholding to separate two score distributions

we recompute the threshold based on the new score distribution.
This dynamic thresholding technique adapts to the changes in the
score distribution and may be able to reï¬‚ect the size of the ESS
more accurately. In practice we observe that this algorithm slightly
outperforms the static thresholding algorithm.

However, since we are dynamically changing the thresholding
value in the dynamic thresholding algorithm, we cannot guarantee
the convergence property as in the static thresholding algorithm.
Therefore we place a loop-termination condition which is the max-
imum number of iterations to execute for efï¬ciency consideration.
In practice we use small number of iterations (e.g., 5) and observe
reasonable performance.
4.2 Automatic Score Thresholding

The subproblem we look at in this section, is to automatically
determine the natural threshold that best separates two underlying
score distributions from one score distribution. This problem arises
when we have a set of scores, each of which represents an estima-
tion of the likelihood of the term being a member of the â€œconcept
setâ€ we are trying to uncover. The assumption here is that those
terms that really belong to the â€œconcept setâ€ will have higher scores,
and follows some kind of score distribution as in the right curve in
Figure 3; while those that do not belong to the set will have lower
scores, but also follow a score distribution as the left curve in Fig-
ure 3. Under this assumption, the problem becomes the classical
score thresholding problem, and we tap into existing literature to
solve this thresholding problem.

In particular, the same problem arises in image segmentation in
the computer graphics, where the goal is to separate the foreground
image from the background images. For example, in Figure 4, the

Brieï¬‚y, Otsuâ€™s technique sees the two sets of scores separated
by the threshold as two clusters.
It is based on the observation
that the threshold that best separates the two clusters is the point
with the least intra-cluster variances. Therefore, Otsuâ€™s threshold-
ing uses the sum of the two intra-cluster variances as the objec-
tive function, and searches for the point that minimizes the sum
of the intra-cluster variances as the threshold. We observe that in
our experiments, this thresholding technique outperforms alterna-
tive thresholding techniques we experimented with. Given a sorted
list of scores, the Otsuâ€™s threshold can be computed linearly.
4.3 Discussions

Having described the details of our algorithm, here we discuss
some major differences compared with existing random walk based
approaches.

Our algorithms in its essence take an iterative score computation
process, which is very similar to, say random walk based ranking
algorithms which also compute scores iteratively. How is our iter-
ative score computation algorithm different from the general ran-
dom walk? More importantly, as we have noted, we observe in our
experiments that our algorithm outperforms the random walk based
approaches. It is thus interesting to explore the differences between
our approach and the random walk based algorithms that lead to the
divergence in performance.

First, we would like to point out the key similarities between
our iterative score computation and random walk algorithms. If we
were to build a ğ‘ Ã—ğ‘ similarity matrix ğ‘€ where each entry (ğ‘¥, ğ‘¦)
denotes the similarity of terms ğ‘¥ and ğ‘¦ on the left-side of the bipar-
tite graph, this matrix essentially represents a graph between terms
(instead of graph between terms and contexts). In addition, in each
iteration where we aggregate score computation, we are essentially
doing a matrix multiplication ğ›¼ğ‘€ Ã— ğ‘‰ + (1âˆ’ ğ›¼)ğ‘€ Ã— ğ‘‰ â€²
in which

WWW 2011 â€“ Session: Information ExtractionMarch 28â€“April 1, 2011, Hyderabad, India432ğ‘‰ is the (0, 1) vector of size ğ‘ that represents the given seeds,
and ğ‘‰ â€²
is a (0, 1) vector that represents the ESS in the previous
iteration. The computation framework bears some similarity with
random walk based approach.

However, we note that there are at least three important aspects
that differentiate our algorithm from the random walk based ap-
proaches. First, we use a score thresholding mechanism as dis-
cussed in Section 4.2 to ï¬nd a good ESS (equivalently, the multipli-
cation vector ğ‘‰ ), which tends to be very small in size (comparing to
the set of universal terms), as opposed to normal random walk that
does not have such score thresholding. As the result, we only prop-
agate probability (or, scores) through conï¬dent nodes. Secondly,
we normalize scores in each iteration differently. The aggregate
score we compute is a weighted sum of the score computed against
the given seeds and the score computed against the ESS in each
iteration (catching both relevance and coherence), which is differ-
ent from typical random walks that only take care of relevance to
the seeds. Lastly, we treat each entity in the ESS equally and reset
their weights to be â€œ1â€ after each iteration, which is again different
from random walks. Given the speciï¬c set-expansion application
we are targeting at, where each entity in the set should be con-
ceptually treated equally, the reset of weight is reasonable given a
robust automatic score thresholding mechanism. It turns out in our
experimental evaluation that these aspects are critical to achieving
reasonable set expansion performances.

5. EXPERIMENTS
5.1 Experimental Setup
5.1.1 Data Set Preparation
As we have alluded before, we experiment with two types of
data, the web lists and the query log. Both of them are modeled
as bipartite graph as described in Section 3.1. In particular, for the
web list data, we use crawlers to extract around 6 million lists in
HTML pages from the web, and the resulting bipartite graph has
58, 550, 245 edges. For the query log data, we obtain a sample
of user queries from Bing, and the resulting bipartite graph has
94, 859, 646 edges.

To evaluate the effectiveness of our algorithms, we select four
sets of concepts over which set expansion experiments are con-
ducted, namely, country names, colors, camera brands and mattress
brands. The â€œground truthâ€, or the set of entities that is considered
to belong to each concept set are determined as follows. For coun-
try names and colors, we resort to Wikipedia and use the list of
countries in [2] and the list of atomic web browser colors in [3],
respectively. For camera brands and mattress brands, we obtained
the manually created lists from domain experts. We selected these
four categories because (1) they are across different domains; and
(2) they have different degree of difï¬culty for set expansion.

In order to compare the performance of the our algorithms and
the existing techniques, we randomly pick 6 entities from the ground
truth data for each concept set as the input starting seeds. Since
each algorithm returns a ranked list of results, we evaluate the per-
formance of these competing algorithms by measuring the preci-
sion/recall values of each algorithm at different rank positions.
5.1.2 Algorithms/Systems Compared
We conduct three broad groups of experiments to thoroughly un-
derstand the effectiveness of our set expansion algorithms. In the
ï¬rst set of experiments we compare the algorithms proposed in this
work with the state-of-art random-walk based ranking algorithms
used for set expansion, over the same web list/query log data. We

implemented two random-walk based ranking algorithm, the regu-
lar random-walk with ï¬xed teleport probability as used in [17, 18,
19], and the Adsorption random walk algorithm [5, 15, 20], which
essentially is a variant of the regular random-walk, which penal-
izes popular nodes by customizing the teleport probability based
on the edge-degree of each node. In both cases the random walk is
performed on the bipartite graph model as described in Section 3.1.
In addition, we conduct a second group of experiments that com-
pares our algorithms with the two existing software set expansion
systems, namely the SEAL set expansion system [16] and the Google
Sets system [1] through their respective public web portals. Since
SEAL interface only accepts up to 3 seeds, we pick 3 entities as
seeds in this set of experiments.

Lastly, we drill down to the dynamic thresholding algorithm (the
behavior of the static thresholding algorithm is similar) proposed in
this work, and present a set of experiments in which we vary vari-
ous parameters. Speciï¬cally, we vary the parameter ğ›¼, the number
of seeds used, and the similarity metric used, etc. This allows us to
analyze and to better understand the performance characteristics of
our algorithm in response to the changes in parameter values.
5.2 Experimental Results
5.2.1 Example Output

Country
germany
japan
belgium
denmark
canada
spain

poland
sweden
norway
austria
peru
croatia

netherlands

hungary

italy

czech republic

Color
blue
red
white
green
yellow
brown
black
purple
pink
gray
orange
violet
silver
grey
gold

greyish green

switzerland

slovakia
china
slovenia

bronze
beige
navy
tan

Camera
olympus
nikon
kodak
pentax
canon
casio
fuji

panasonic

leica
fujiï¬lm
sony
ricoh
vivitar
sigma

Mattress

serta
sealy

simmons
beautyrest

sealy posturepedic

stearns foster

bassett

tempur pedic

sears

spring air
gold bond

jobri

universal furniture

champlain

konica minolta

samsung
minolta
polaroid
vistaquest

rollei

fbg

coapt systems

riverside furniture

hyla vacuum

broyhill

lifestyle solutions

Table 1: Top-20 results by Dynamic Thresholding algorithm

Table 1 lists the top 20 ranked results produced by dynamic
thresholding algorithm for the four domains that we experiment
with. The static thresholding algorithm reports similar results, as
we will see later in the precision/recall curves. In each domain,
those terms in boldface are the input seeds. The underlined terms
are the results that do not belong to the ground truth set and thus
counted as incorrect results; while the remaining terms are correct
results expanded from the input seeds.

From Table 1, we can see that in the top-20 ranked results, the
â€œCountryâ€ and â€œCameraâ€ domains have perfect precision. â€œColorâ€
domain has only one incorrect result â€œgreyish greenâ€ (which al-
though being a real composite color, is nonetheless not included in
our ground truth set which only includes atomic colors). The top-
20 results for â€œMattressâ€, however, includes many noisy entires that
are incorrect, including product line names (â€œsealy posturepedicâ€
and â€œbeautyrestâ€), and furniture retailers (â€œuniversal furnitureâ€ and
â€œriverside furnitureâ€).

WWW 2011 â€“ Session: Information ExtractionMarch 28â€“April 1, 2011, Hyderabad, India4331

0.5

l
l

a
c
e
R

0

0

1

0.5

l
l

a
c
e
R

0

0

Dynamic(cid:3)Threshold
Static(cid:3)Threshold
Random(cid:3)Walk
Random(cid:3)Walk(cid:3)Adsp

0.5

Precision
(a) Country

Dynamic(cid:3)Threshold
Static(cid:3)Threshold
Random(cid:3)Walk
Random(cid:3)Walk(cid:3)Adsp

0.5

Precision
(c) Camera

1

l
l

a
c
e
R

0.5

1

0

0

0.8

0.6

l
l

a
c
e
R

0.4

0.2

0

0

1

Dynamic(cid:3)Threshold
Static(cid:3)Threshold
Random(cid:3)Walk
Random(cid:3)Walk(cid:3)Adsp

0.5

Precision

(b) Color

Dynamic(cid:3)Threshold
Static(cid:3)Threshold
Random(cid:3)Walk
Random(cid:3)Walk(cid:3)Adsp

1

0.5

l
l

a
c
e
R

1

0

0

0.6

0.4

0.2

l
l

a
c
e
R

Dynamic(cid:3)Threshold
Static(cid:3)Threshold
Random(cid:3)Walk
Random(cid:3)Walk(cid:3)Adsp

0.5

Precision
(a) Country

Dynamic(cid:3)Threshold
Static(cid:3)Threshold
Random(cid:3)Walk
Random(cid:3)Walk(cid:3)Adsp

0.6

0.4

l
l

a
c
e
R

0.2

0

0

1

0.6

0.4

l
l

a
c
e
R

0.2

Dynamic(cid:3)Threshold
Static(cid:3)Threshold
Random(cid:3)Walk
Random(cid:3)Walk(cid:3)Adsp

0.5

Precision

(b) Color

1

Dynamic(cid:3)Threshold
Static(cid:3)Threshold
Random(cid:3)Walk
Random(cid:3)Walk(cid:3)Adsp

1

0

0

0.5

Precision
(d) Mattress

0.5

Precision
(c) Camera

0

0

1

0.5

Precision
(d) Mattress

1

Figure 5: Comparison with Random-Walk based approach using
Web List data

Figure 6: Comparison with Random-Walk based approach using
Query Log data

Observing the patterns of the incorrect results in the ranked list,
we further adopt a token-based subset/superset-ï¬ltering heuristics
to remove results that are likely to be incorrect. Speciï¬cally, we
remove a result in the ranked list if there is another result that ranks
higher in the list whose token set is a subset/superset of the cur-
rent result. The intuition here is that for a pair of results whose
token sets are subset-superset, the concepts that they represent also
tend to constitute a semantic superclass-subclass hierarchy. Given
that we are expanding the given seeds to produce a coherent con-
cept set, one and at most one of the two entities in the superclass-
subclass hierarchy can be correct. Therefore, we only pick the re-
sult that ranks higher (a more conï¬dent prediction) and ignore sub-
set/superset results that rank lower. As an example, since â€œsealyâ€
ranks higher in the list for â€œMattressâ€, we will not consider the su-
perset result â€œsealy posturepedicâ€ that ranks lower, which is only
a product line, or a subclass of the desired superclass concept, the
manufacturer/brand name â€œsealyâ€. Similarly â€œgreyish greenâ€ will
not be considered since the subset â€œgreenâ€ is also a result that ranks
higher. This simple heuristic turns out to be useful and boosts the
precision/recall results. We apply this token-based subset/superset-
ï¬ltering for all algorithms/systems in our experiments.
5.2.2 Comparison With Random Walk
In this section we present the performance comparison between
the iterative thresholding algorithm proposed in this work, and the
random walk based ranking algorithms.

For the random walk based approaches, we report experimen-
tal results for both the regular random walk [17, 18, 19], and the
Adsorption random walk [5, 15, 20], on the bipartite graph as mod-
eled in Section 3.1. They are reported as the â€œRandom Walkâ€ and
â€œRandom Walk Adspâ€ curves. We set teleport probability as 0.2.

Figure 5 shows the performance results on the Web List data for
each of the four domains that we experimented with. Note that
while Dynamic Thresholding is slightly better than Static Thresh-

olding, both approaches signiï¬cantly outperform random walk based
approaches. This conï¬rms that simple random walk based ap-
proach is not able to handle noisy data well, as we analyzed in
Section 4.3.

Figure 6 presents the same experiments run on the Query Log
data. The general trends observed in Figure 5 is conï¬rmed: Dy-
namic Thresholding and Static Thresholding outperforms the ran-
dom walk based approaches quite signiï¬cantly. We note, however,
that the precision/recall results observed on Query Log data are not
as good as the those on Web List data. This is not entirely surpris-
ing, as the query log tends to be much noisier than the HTML web
lists.

5.2.3 Comparison with Google Sets and SEAL
We additionally conduct a second group of experiments that com-
pares our algorithms against two existing systems, SEAL [16] and
Google Sets [1] 1. As we stated previously, since we do not have
complete details of the implementation of the algorithms or the
back-end data set used by either of the SEAL/Google Sets systems,
the performance numbers do not directly compare. However, we
still feel that reporting these results is useful in that it puts the per-
formance of our algorithm in the context of start-of-art existing sys-
tems, and helps us to understand the usefulness of the algorithms.
Figure 7 summarizes the performance comparison between Dy-
namic Thresholding that we propose, and SEAL/Google Sets. Since
web interface for Google Sets can take up to 5 seeds, while SEAL
can only allow for 3 seeds as input, in this set of experiments we
only use 3 seeds as input to all three algorithms. In addition, as
Google Sets only returns 50 results at most, its performance curve
is incomplete (especially for the â€œCountryâ€ domain, where we re-
port precision/recall up to the top-ranked 500 terms given that the

1performance numbers for SEAL and Google Sets were obtained
on 10/01/2010

WWW 2011 â€“ Session: Information ExtractionMarch 28â€“April 1, 2011, Hyderabad, India434l
l

a
c
e
R
/
n
o
i
s
i
c
e
r
P

0.8
0.78
0.76
0.74
0.72
0.7
0.68
0.66
0.64
0.62
0.6

Precision
Recall

l
l

a
c
e
r
/
n
o
i
s
i
c
e
r
p

0.4

0.35

0.3

0.25

0.2

0.15

0.1

0.05

0

DT(cid:3)3(cid:3)seeds
Google(cid:3)Set(cid:3)3(cid:3)seeds
SEAL(cid:3)3(cid:3)seeds

0

0.5

Precision

1

0

0.3

0.5
alpha

0.8

1

(b) Color

(a) Camera

Precision
Recall

0

0.3

0.5
alpha

0.8

1

(b) Mattress

l
l

a
c
e
R

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

l
l

a
c
e
R

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

0

l
l

a
c
e
R

1

l
l

a
c
e
R

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0.5
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0

DT(cid:3)3(cid:3)seeds
Google(cid:3)Set(cid:3)3(cid:3)seeds
SEAL(cid:3)3(cid:3)seeds

0.5

Precision
(a) Country

DT(cid:3)3(cid:3)seeds
Google(cid:3)Set(cid:3)3(cid:3)seeds
SEAL(cid:3)3(cid:3)seeds

1

0.5

Precision
(c) Camera

DT(cid:3)3(cid:3)seeds
Google(cid:3)Set(cid:3)3(cid:3)seeds
SEAL(cid:3)3(cid:3)seeds

0

0.5

Precision
(d) Mattress

1

l
l

a
c
e
R

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

Jaccard
Cosine

Figure 8: Sensitivity analysis to ğ›¼

#(cid:3)seed(cid:3)=(cid:3)2
#(cid:3)seed(cid:3)=(cid:3)4

l
l

a
c
e
R

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

0.5

Precision

1

0

0.2

0.4

Precision

0.6

0.8

(a) Vary similarity metric

(b) Vary # of seeds

Figure 9: Sensitivity analysis

mance in most cases, and adopt ğ›¼ = 0.5 in all remaining experi-
ments.

Next, in Figure 9a we vary the similarity metric used in our
Dynamic Thresholding algorithm for the â€œCameraâ€ domain. Re-
call that our algorithm is a general framework that can work with
any similarity measurements. In this experiment we report perfor-
mance of our algorithm using both Jaccard similarity and the Co-
sine similarity metric. As can be seen in Figure 9a, while both ap-
proaches perform reasonably well, the Cosine similarity is slightly
better. Similar trends are also observed in experiments over other
domains, conï¬rming the performance advantage of using Cosine
similarity. Therefore, we only report performance using Cosine
similarity metric in all other experiments.

Finally, in Figure 9b, we vary the number of input seeds and
report the corresponding set expansion performance. Speciï¬cally,
given the 6 seeds we used for each of the four domains in the pre-
vious experiments, we pick all possible 2-seed combination out of
these 6 seeds, which gives us a total of 15 such combinations. Sim-
ilarly we pick all possible 4-seed combination out of the 6 seeds
which again gives us 15 possibilities. We then use all 15 combina-
tions of 2/4 seeds as input, to test the performance of our Dynamic
Thresholding algorithm. The results are reported in Figure 9b. The
overall trend that stands out in this ï¬gure is that the performance of
our algorithm with 4 seeds is in general much better and more sta-
ble than the case where only 2 seeds are used as input. Observe that
to the lower left corner, there are two instances of 2-seed combina-
tions that lead to extremely low precision/recall. This suggests that
our algorithm is more robust when a reasonable number of seeds
are given, and the performance may ï¬‚uctuate with very few num-
ber of seeds, largely depending on the quality of the seeds given.
However, we believe that it is not really hard to ï¬nd 4 input seeds
in virtually any domain, thus not a stringent requirement in general,
ensuring the usefulness of our algorithm.

Figure 7: Comparison with Google Sets and SEAL

ground-truth set is much larger for â€œCountryâ€). The general ob-
servation is that while Dynamic Thresholding and Google Sets per-
form roughly the same in â€œCountryâ€ and â€œColorâ€, Dynamic Thresh-
olding has a slightly better precision/recall curve for â€œCameraâ€ and
â€œMattressâ€. Furthermore, in each of the four domains Dynamic
Thresholding seems to outperforms the SEAL system. Neverthe-
less, we once again emphasize that this is by no means an implica-
tion of the relative performance of these algorithms. The difference
in performance may simply because of the different data sets each
system uses. It does suggest, however, that the algorithm we de-
velop is competitive against existing set-expansion systems.

Sensitivity Analysis to Parameters

5.2.4
To better understand the performance characteristics of our pro-
posed approaches, we in this section conduct sensitivity analysis
to understand the impact of various parameters to our algorithm.
Again, we use the dynamic thresholding algorithm as example.

Figure 8 depicts the performance of the Dynamic Thresholding
algorithm with varied parameter ğ›¼ in domain â€œCameraâ€ and â€œMat-
tressâ€. Recall that in Deï¬nition 4, ğ›¼ is the essentially the weight
parameter used to balance the quality metric of the expanded seed
set (ESS) between relevance and coherence. ğ›¼ = 0 means that we
only consider the coherence of ESS, while ğ›¼ = 1 indicates that
only relevance is taken into account. Any value of ğ›¼ in between
suggests a combination of both of these two metrics. In both Fig-
ure 8a and Figure 8b we can see that when ğ›¼ gets extreme values (0
or 1, meaning only one of the relevance and coherence metrics is
considered), precision/recall performance numbers suffer. On the
other hand, ğ›¼ values in between boosts the performance of our al-
gorithm. While we only report performance for domain â€œCameraâ€
and â€œMattressâ€ here, similar trends are observed in other domains.
In general, we observe that ğ›¼ = 0.5 usually gives the best perfor-

WWW 2011 â€“ Session: Information ExtractionMarch 28â€“April 1, 2011, Hyderabad, India4356. CONCLUSION

In this paper we studied the problem of using general-purpose
web data (web lists and query logs) to expand a set of seed entities.
We proposed a simple yet effective quality metric to measure the
expanded set, and designed two iterative thresholding algorithms
to rank candidate entities. We validated our approach using exper-
iments conducted on multiple domains, and concluded that our al-
gorithm outperforms existing techniques for set expansion on noisy
web data.

7. REFERENCES
[1] Google Sets: http://labs.google.com/sets.
[2] List of United Nations member states.

http://en.wikipedia.org/wiki/united_nations_member_states.

[3] Web colors. http://en.wikipedia.org/wiki/web_colors.
[4] E. Agichtein and L. Gravano. Snowball: extracting relations from

large plain-text collection. In JCDL, 2000.

[5] S. Baluja, R. Seth, D. Sivakumar, Y. Jing, J. Yagnik, S. Kumar,

D. Ravichandran, and M. Aly. Video suggestion and discovery for
youtube: Taking random walks through the view graph. In WWW,
2008.

[6] O. Etzioni, M. Cafarella, D. Downey, S. Kok, A. Popescu, T. Shaked,

S. Soderland, D. S. Weld, and A. Yates. Web-scale information
extraction in KnowItAll. In WWW, 2004.

[7] O. Etzioni, M. Cafarella, D. Downey, A.-M. Popescu, T. Shaked,

S. Soderland, D. S. Weld, and A. Yates. Unsupervised named-entity
extraction from the web: An experimental study. In Artiï¬cal
Intelligence, 2005.

[8] Z. Ghahramani and K. A. Heller. Bayesian sets. In NIPS, 2005.
[9] R. M. Karp. Reducibility among combinatorial problems. Complexity

of Computer Computations, 1972.

[10] N. Otsu. A threshold selection method from gray-level histograms.

IEEE Transactions on Systems, Man and Cybernetics, 1979.

[11] M. S. Pang-Ning Tan and V. Kumar. Introduction to Data Mining.

2005.

[12] T. Ridler and S. Calvard. Picture thresholding using an iterative

selection method. IEEE Transactions on Systems, Man and
Cybernetics, 1978.

[13] B. Settles. Biomedical named entity recognition using conditional

random ï¬elds and rich feature sets. In CoLING, 2004.

[14] P. P. Talukdar, T. Brants, M. Liberman, and F. Pereira. A context
pattern induction method for named entity extraction. In CoNLP,
2006.

[15] P. P. Talukdar, J. Reisinger, M. Pasca, D. Ravichandran, R. Bhagat,

and F. Pereira. Weakly-supervised acquisition of labeled class
instances using graph random walks. In EMNLP, 2008.
[16] R. Wang and W. Cohen. SEAL: http://rcwang.com/seal.
[17] R. Wang and W. Cohen. Language-independent set expansion of

named entities using the web. In ICDM, 2007.

[18] R. Wang and W. Cohen. Iterative set expansion of named entity using

the web. In ICDM, 2008.

[19] R. Wang and W. Cohen. Character-level analysis of semi-structured

documents for set expansion. In EMNLP, 2009.

[20] Y.-Y. Wang, R. Hoffmann, X. Li, and J. Szymanski. Semi-supervised
learning of semantic classes for query understanding. In CIKM, 2009.

8. APPENDIX
8.1 Proof of Theorem 1

We show that there exists a polynomial-time reduction from the
Maximum-Clique problem to the problem we stated in Section 3.4.
For any given graph ğº = {ğ‘‰, ğ¸} for which the Maximum-
Clique needs to be computed, we can build a corresponding simi-
larity matrix ğ‘€ of size âˆ£ğ‘‰ âˆ£Ã—âˆ£ğ‘‰ âˆ£, where each row ğ‘Ÿğ‘– corresponds to
vertex ğ‘£ğ‘– âˆˆ ğ‘‰ , and each column ğ‘ğ‘— corresponds to vertex ğ‘£ğ‘— âˆˆ ğ‘‰ .
The matrix entry ğ‘€ (ğ‘Ÿğ‘–, ğ‘ğ‘—) is 1 if there is the edge (ğ‘£ğ‘–, ğ‘£ğ‘—) âˆˆ ğ¸,
otherwise ğ‘€ (ğ‘Ÿğ‘–, ğ‘ğ‘—) = 0.

Given this construction of this similarity matrix ğ‘€, we prove
the claim by contradiction. Suppose there is an algorithm ğ´ that
efï¬ciently ï¬nds the optimal ğ‘… of size ğ¾ with maximum quality
ğ‘„(ğ‘…, ğ‘†). If we assign ğ›¼ to be 0, the decision problem of ï¬nding
Maximum-Clique of any graph ğº can be solved using the corre-
sponding similarity matrix ğ‘€ and algorithm ğ´. This is because the
âˆ£ğ‘…âˆ£âˆ’1
optimal set ğ‘… computed by ğ´ with maximum quality score (
2âˆ£ğ‘…âˆ£ )
must corresponds to a clique in the original graph. This contra-
dicts with the hardness of the Maximum-Clique problem, hence
the hardness of the problem we stated in Section 3.4.
8.2 Proof of Theorem 2

Let ğ‘… = {ğ‘Ÿ1, ğ‘Ÿ2, ..., ğ‘Ÿğ¾âˆ’1, ğ‘Ÿğ¾} and ğ‘…â€² = {ğ‘Ÿâ€²

To prove that the Algorithm 1 will terminate and the computation
of ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿ converges, we show that the quality metric ğ‘„(ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿ, ğ‘†) is
monotonically increasing with the number of iteration ğ‘–ğ‘¡ğ‘’ğ‘Ÿ.
ğ¾}
ğ¾âˆ’1, ğ‘Ÿâ€²
2, ..., ğ‘Ÿâ€²
be the ESS of two subsequent iterations. Without loss of generality,
ğ‘– for 1 â‰¤ ğ‘– â‰¤ ğ¾âˆ’1, and denote Ëœğ‘… = {ğ‘Ÿ1, ğ‘Ÿ2, ..., ğ‘Ÿğ¾âˆ’1} =
let ğ‘Ÿğ‘– = ğ‘Ÿâ€²
{ğ‘Ÿâ€²
ğ¾âˆ’1}, such that we have ğ‘… = Ëœğ‘… âˆª {ğ‘Ÿğ¾} and ğ‘…â€² =
2, ..., ğ‘Ÿâ€²
1, ğ‘Ÿâ€²
Ëœğ‘… âˆª {ğ‘Ÿâ€²
ğ¾}. Let ğ‘”(ğ‘Ÿğ‘—, ğ‘…, ğ‘†), and ğ‘”(ğ‘Ÿğ‘—, ğ‘…â€², ğ‘†) be the ranking func-
tion of ğ‘Ÿğ‘— against ğ‘… and ğ‘…â€²
respectively. Observe that the quality
metric

1, ğ‘Ÿâ€²

ğ‘„(ğ‘…, ğ‘†) =

ğ›¼

âˆ£ğ‘…âˆ£ â‹… âˆ£ğ‘†âˆ£

âˆ£ğ‘†âˆ£âˆ‘

âˆ£ğ‘…âˆ£âˆ‘

ğ‘–=1

ğ‘—=1

ğ‘†ğ‘–ğ‘š(ğ‘ ğ‘–, ğ‘Ÿğ‘—)

(1 âˆ’ ğ›¼)
âˆ£ğ‘…âˆ£ â‹… âˆ£ğ‘…âˆ£

+

âˆ£ğ‘…âˆ£âˆ‘

âˆ£ğ‘…âˆ£âˆ‘

ğ‘–=1

ğ‘—>ğ‘–

ğ‘†ğ‘–ğ‘š(ğ‘Ÿğ‘–, ğ‘Ÿğ‘—)

and similarly

ğ‘„(ğ‘…â€², ğ‘†) =

ğ›¼

âˆ£ğ‘…â€²âˆ£ â‹… âˆ£ğ‘†âˆ£

âˆ£ğ‘†âˆ£âˆ‘

âˆ£ğ‘…â€²âˆ£âˆ‘

ğ‘–=1

ğ‘—=1

ğ‘†ğ‘–ğ‘š(ğ‘ ğ‘–, ğ‘Ÿâ€²
ğ‘—)

(1 âˆ’ ğ›¼)
âˆ£ğ‘…â€²âˆ£ â‹… âˆ£ğ‘…â€²âˆ£

+

âˆ£ğ‘…â€²âˆ£âˆ‘

âˆ£ğ‘…â€²âˆ£âˆ‘

ğ‘–=1

ğ‘—>ğ‘–

ğ‘†ğ‘–ğ‘š(ğ‘Ÿâ€²

ğ‘–, ğ‘Ÿâ€²
ğ‘—)

The difference of the quality function in two subsequent itera-

.

tions are thus

ğ‘„(ğ‘…â€², ğ‘†) âˆ’ ğ‘„(ğ‘…, ğ‘†)

=

âˆ£ğ‘†âˆ£âˆ‘

ğ›¼

ğ‘–=1

âˆ£ğ‘…âˆ£ â‹… âˆ£ğ‘†âˆ£ (
(1 âˆ’ ğ›¼)
âˆ£ğ‘…âˆ£ â‹… âˆ£ğ‘…âˆ£ (
âˆ£ğ‘†âˆ£âˆ‘

+

ğ‘–=1

âˆ£ğ‘…âˆ£ â‹… âˆ£ğ‘†âˆ£ (
(1 âˆ’ ğ›¼)
âˆ£ğ‘…âˆ£ â‹… âˆ£ğ‘…âˆ£ (

+

â‰¥ ğ›¼

ğ‘†ğ‘–ğ‘š(ğ‘ ğ‘–, ğ‘Ÿâ€²

ğ¾âˆ’1âˆ‘

ğ‘†ğ‘–ğ‘š(ğ‘Ÿâ€²

âˆ£ğ‘†âˆ£âˆ‘

ğ¾ ) âˆ’
ğ¾ , ğ‘Ÿğ‘–) âˆ’ ğ¾âˆ’1âˆ‘

ğ‘–=1

ğ‘–=1

ğ‘–=1

ğ‘†ğ‘–ğ‘š(ğ‘ ğ‘–, ğ‘Ÿâ€²

ğ¾âˆ‘

ğ‘†ğ‘–ğ‘š(ğ‘Ÿâ€²

âˆ£ğ‘†âˆ£âˆ‘

ğ¾ ) âˆ’
ğ¾ , ğ‘Ÿğ‘–) âˆ’ ğ¾âˆ‘

ğ‘–=1

ğ‘–=1

ğ‘–=1

ğ‘†ğ‘–ğ‘š(ğ‘ ğ‘–, ğ‘Ÿğ¾ ))

ğ‘†ğ‘–ğ‘š(ğ‘Ÿğ¾ , ğ‘Ÿğ‘–))

ğ‘†ğ‘–ğ‘š(ğ‘ ğ‘–, ğ‘Ÿğ¾ ))

ğ‘†ğ‘–ğ‘š(ğ‘Ÿğ¾ , ğ‘Ÿğ‘–))

â‰¥ 1
âˆ£ğ‘…âˆ£ (ğ‘”(ğ‘Ÿâ€²

ğ¾ , ğ‘…, ğ‘†) âˆ’ ğ‘”(ğ‘Ÿğ¾ , ğ‘…, ğ‘†))

>0.

In other words, after each iteration the quality of the new ESS
ğ‘„(ğ‘…â€², ğ‘†) is strictly greater than that of the previous iteration ğ‘„(ğ‘…, ğ‘†).
Since for each iteration ğ‘–ğ‘¡ğ‘’ğ‘Ÿ, ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿ âŠ† ğ‘ˆ, the number of different
ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿ is ï¬nite. Thus we know the algorithm will terminate and the
computation of ğ‘…ğ‘–ğ‘¡ğ‘’ğ‘Ÿ converges.

WWW 2011 â€“ Session: Information ExtractionMarch 28â€“April 1, 2011, Hyderabad, India436