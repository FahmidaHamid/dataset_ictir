Personalized Recommendation on Dynamic Content

Using Predictive Bilinear Models

Wei Chu
Yahoo! Labs.

2821 Mission College Blvd

Santa Clara, CA 95054

chuwei@yahoo-inc.com

Seung-Taek Park

Yahoo! Labs.

2821 Mission College Blvd

Santa Clara, CA 95054

parkst@yahoo-inc.com

ABSTRACT
In Web-based services of dynamic content (such as news arti-
cles), recommender systems face the diÔ¨Éculty of timely iden-
tifying new items of high-quality and providing recommen-
dations for new users. We propose a feature-based machine
learning approach to personalized recommendation that is
capable of handling the cold-start issue eÔ¨Äectively. We main-
tain proÔ¨Åles of content of interest, in which temporal charac-
teristics of the content, e.g. popularity and freshness, are up-
dated in real-time manner. We also maintain proÔ¨Åles of users
including demographic information and a summary of user
activities within Yahoo! properties. Based on all features
in user and content proÔ¨Åles, we develop predictive bilinear
regression models to provide accurate personalized recom-
mendations of new items for both existing and new users.
This approach results in an oÔ¨Ñine model with light computa-
tional overhead compared with other recommender systems
that require online re-training. The proposed framework is
general and Ô¨Çexible for other personalized tasks. The supe-
rior performance of our approach is veriÔ¨Åed on a large-scale
data set collected from the Today-Module on Yahoo! Front
Page, with comparison against six competitive approaches.

Categories and Subject Descriptors
H.1.0 [Models and Principles]: General; H.3.3 [Information
Search and Retrieval]: Information Ô¨Åltering; H.3.5 [Online
Information Services]: Web-based services

General Terms
Algorithms, Experimentation, Design, Performance

Keywords
Personalization, Dynamic Features, Bilinear, Regression, Rank-
ing, User and Content ProÔ¨Åles, Recommender Systems

1.

INTRODUCTION

The Internet provides an unparalleled opportunity for or-
ganizations to deliver digital content to their visitors instan-
taneously. Content consumers usually have short attention
span, while possibly a large number of content venders. The

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2009, April 20‚Äì24, 2009, Madrid, Spain.
ACM 978-1-60558-487-4/09/04.

biggest challenge most organizations face is not lack of con-
tent, but how to optimize the content they already own by
identifying the most appropriate customers at the right time.
Personalized recommendation has become a desirable fea-
ture of e-business Web sites to improve customer satisfaction
and customer retention [8], by tailoring content presentation
to suit an individual‚Äôs needs rather than take the traditional
‚Äúone-size-Ô¨Åts-all‚Äù approach.

Personalized recommendation involves a process of gath-
ering and storing information about site visitors, managing
the content assets, analyzing current and past user inter-
active behavior, and, based on the analysis, delivering the
right content to each visitor [31]. Search engines help in-
dex available content assets and return relevant information
to users, if the users are looking for something speciÔ¨Åc that
can be summarized as a keyword query. However, in many
cases, users are looking for things might interest them, but
do not have concrete desideration in mind when browsing a
Web site. In such cases, it is a recommendation engine that
presents the most plausible content that the user may want,
based on her interests as demonstrated by her past activities.
Traditional recommendation engines could be distinguished
into three diÔ¨Äerent approaches: rule-based Ô¨Åltering, content-
based Ô¨Åltering, and collaborative Ô¨Åltering [32]. Rule-based
Ô¨Åltering creates a user-speciÔ¨Åc utility function and then ap-
plies it to the items under consideration. This approach
is closely related to customization, which requires users to
identify themselves, conÔ¨Ågure their individual settings, and
maintain their personalized environment over time [21]. It
is easy to fail since the burden of responsibility falls on the
users. Content-based Ô¨Åltering generates a proÔ¨Åle for a user
based on the content descriptions of the items previously
rated by the user. The main drawback of this approach is
the recommended items are similar to the items previously
seen by the user. Mladenic [30] provided a survey of the com-
monly used text-learning techniques in the context of con-
tent Ô¨Åltering. Collaborative Ô¨Åltering (CF) is one of the most
successful and widely used recommender system technology
[37]. CF analyzes users‚Äô ratings to recognize commonalities
between users on the basis of their historical ratings, and
then generates new recommendations based on like-minded
users‚Äô preferences. CF provides a good solution to ‚Äúa closed
world‚Äù, where overlaps in ratings across users are relatively
high and the universe of content items is almost static.

In many scenarios, such as news Ô¨Åltering [15], where the
content universe changes rapidly and signiÔ¨Åcant portion of
users are new users, CF will suÔ¨Äer from the cold-start prob-
lem. Several hybrid recommender systems have been devel-

WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems691oped to tackle the cold-start problem by combining two or
more recommendation techniques. The inability of CF to
recommend new items is commonly leveraged by coupling
with a content-based Ô¨Åltering, such as in Fab [3], a recom-
mender system for the Web content. Burke [10] provided a
comprehensive analysis of approaches to generating hybrid
recommendation engines.

Although hybridization can alleviate some of the weak-
nesses associated with CF and other recommendation tech-
niques, there are still a few important issues that haven‚Äôt
been well studied in literature:

‚Ä¢ Dynamic Content: We consider not only the item set
undergoes insertions and deletions frequently, but also
the content value and then the appraisement from users
are changing rapidly as well. For example, the lifetime
of breaking news on the Internet is usually a couple of
hours, and the value of the news (such as click through
rate) is decaying temporally as people get to know it,
see Figure 3(a) for an example. Traditional recom-
mender systems usually treat users‚Äô feedback static, so
that feedback on the same items given at diÔ¨Äerent time
stamps is still comparable. This assumption doesn‚Äôt
hold on dynamic content. Rebuilding the model on
very recent data is typically an expensive task, and
tends to lose long-term interests of users. On dynamic
content, recommender systems always face the cold-
start problem for new items.

‚Ä¢ Users with Open ProÔ¨Åles: A typical user proÔ¨Åle in a
CF system is a list of ratings on items of interest. In
practice, we can legally collect user information to de-
velop a general proÔ¨Åle for a site visitor [19], which is
not limited to the content universe only. The gen-
eral proÔ¨Åle may include declared demographic informa-
tion, activities on relevant sites, consumption history,
etc. The objective is to provide valuable insight into
users‚Äô preferences, interests and wants. Clearly, the
general proÔ¨Åle can help tackle the cold-start problem
on new users. Demographic recommender systems, e.g.
[34], aim to segment users based on personal attributes
and make recommendations according to demographic
classes. However, the history of user ratings and con-
tent features haven‚Äôt been jointly exploited to form
‚Äúpeople-to-people‚Äù correlation.

In this paper, we propose a machine learning approach
to handling both issues in personalized recommendation.
The key idea is to maintain proÔ¨Åles for both content and
users, and build a feature-based bilinear regression model
to quantify the associations between heterogeneous features
by Ô¨Åtting the historical interactive data. The feature-based
predictive model can then be applied to recommending new
and existing items for both new and existing users.

The goodness of dynamic content over time is a crucial
ingredient in content management. We insert dynamic fea-
tures, such as instantaneous click-through rate (CTR) to in-
dicate temporal popularity, into the content feature set. We
continuously update these dynamic features in the delivery
phase by aggregating users‚Äô interactions over content items
in a real-time manner. We demonstrate that maintaining
content proÔ¨Åles with dynamic features is an eÔ¨Äective strat-
egy to overcome the cold-start problem on dynamic content.

Figure 1: An illustration of unfolding a multi-
dimensional event.

The open proÔ¨Åles of users provide valuable information
about user preferences and interests that helps in recom-
mending content for new users. Historical feedback given by
users on content of interest, such as ratings or click stream,
directly reveals users‚Äô opinion on the content universe. The
bilinear regression models we proposed can discover associa-
tion patterns between the general user proÔ¨Åles and the con-
tent features by exploiting the interactive data (the typical
user proÔ¨Åle in traditional CF). The established associations
are then applied to evaluating individualized appraisement
over currently available items for accurate and prompt per-
sonalized recommendations in real time.

This work is motivated by a personalized content opti-
mization task for the Today-Module on Yahoo! Front Page.
The eÔ¨Äectiveness of the bilinear models is veriÔ¨Åed on a large-
scale real-world data set collected in the application. This
approach results in an oÔ¨Ñine model except online tracked
dynamic features in content proÔ¨Åles. The computational
overhead in online recommendation is minor compared with
recommender systems that require online re-training. The
framework is general and Ô¨Çexible, which can be adapted to
other personalized tasks.

The paper is organized as follows: We introduce data rep-
resentation in Section 2, which includes content proÔ¨Åling,
user proÔ¨Åling and interactive feedback; In Section 3 we de-
scribe a family of probabilistic bilinear models in detail that
covers training algorithms and further discussions on poten-
tial capabilities; We review related work in Section 4; We re-
port the experimental results on the data set collected from
the Today-Module with comparison against six competitive
alternatives in Section 5 and conclude in Section 6.

2. DATA REPRESENTATION

The observational data is naturally recorded in multi-
dimensional format. A logistic event is associated with at
least three types of objects, user √ó content √ó timestamp.
These multi-dimensional events can always be Ô¨Çattened into
two-way form without loss of generality, see Figure 1 for an
illustration. In personalization on dynamic content, we can
treat content√ótimestamp as items of interest. Note that the
dimension of timestamp is usually not considered in tradi-
tional recommender systems. The Ô¨Çattened dimensions form
a new content item space, in which features are extracted
for proÔ¨Åling. We generate and maintain three sets of data:
content proÔ¨Åles, user proÔ¨Åles, and interactive feedback on
content items of interest.
2.1 Content ProÔ¨Åles

When a content is either created or acquired, the informa-

User(cid:13)Item(cid:13)Timestamp(cid:13)User(cid:13)Item at(cid:13)timestamp(cid:13)WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems692tion related to the content, such as manufacturer, product
name and categories etc., constitutes an initial part of the
proÔ¨Åle. Continuous reÔ¨Ånement of the content proÔ¨Åle helps to
optimize the use of the content assets. In the delivery phase,
the content is delivered to users and interactions on the con-
tent are logged and analyzed, providing the ability to assess
the content popularity in a real-time manner. The content
popularity over time is a crucial ingredient in content man-
agement, since the commercial value of most content is vary-
ing or decaying temporally, especially for breaking news.

We consider generalized content items here, which are re-
deÔ¨Åned with both temporal characteristics and other condi-
tions. In a content proÔ¨Åle, there are at least two groups of
features:

‚Ä¢ Static descriptors: Such as categories, manufacturer

name, title, bag of words of textual content etc.

‚Ä¢ Temporal characteristics: Such as popularity, click-
through rate (CTR) and price at current time stamp
or the hours elapsed after content acquisition.

We can collect any features related to the content items.
For example, in search the items become webpages fused
with a query, and then joint features, such as contextual
co-occurrences, can be constructed.

Each content is represented as a vertical vector, denoted

by z, where z ‚àà 4C and C is the number of content features.
2.2 User ProÔ¨Åles

The objective of collecting visitor information is to de-
velop a user proÔ¨Åle that describes a site visitor‚Äôs interests,
consumption history, and other descriptors important to the
site owner. A review of various user proÔ¨Åling techniques is
provided in [19]. Explicit proÔ¨Åling requests each visitor to
declare personal information, such as age, gender and occu-
pation, or to Ô¨Åll out questionnaires that explicitly state their
preferences. Implicit proÔ¨Åling tracks the visitors‚Äô behavior
and it is generally transparent to the visitor. Browsing and
purchasing patterns are the behaviors most often assessed.
The proÔ¨Åle combined with demographic, transaction, and
navigation data implicitly represents a user‚Äôs preferences and
recent interests.

The user feature space is spanned by legally usable fea-
tures. Each user is represented as a vertical vector, denoted

by x, where x ‚àà 4D and D is the dimensionality of the user

feature space.

2.3

Interactive Feedback

In traditional collaborative Ô¨Åltering (CF), the feedback
given by users on content of interest are used as user proÔ¨Åles
to evaluate commonalities between users. In our regression
approach, we separate the feedback from user proÔ¨Åles. The
feedback on content of interest is utilized as targets that
relate patterns in user features to content features.

Although the interactions between the users and the avail-
able items vary depending on the types of items involved,
we can always observe or measure some feedback from user
side. For example, a user may purchase a product or a ser-
vice after review, and even rate it later. For a content posted
on a Web page, a user may click to see more details. The
ratings and actions (click or not, purchase or not) provide

explicit feedback.1 There are a range of eÔ¨Äorts attempted to
measure various kinds of implicit feedback indicators from
linger time [13] to eye movements [36]. We focus on two
types of feedback in this paper:

‚Ä¢ Continuous scores: most implicit feedback and ratings

can be converted as continuous scores.

‚Ä¢ Binary actions: such as click or not, purchase or not

after reviewing an item.

We have collected three sets of data, including content
features, user proÔ¨Åles and interactive data between users and
items. Let index the i-th user as xi and the j-th content item
as zj, and denote by rij the interaction between the user xi
and the item zj. We only observe interactions on a small
subset of all possible user/item pairs, and denote by  the
set of observations {rij}.

3. BILINEAR REGRESSION MODELS

The user and content proÔ¨Åles provide timely descriptions
of users and items respectively. As the two feature spaces
are usually dichotomous, it is hard to apply the contextual
data mining techniques [9] here. However, the interactive
feedback reveals the correlations between user patterns and
content features. In this section, we describe a family of pre-
dictive bilinear models to discover pattern aÔ¨Énities between
heterogeneous features. A set of weight coeÔ¨Écients is in-
troduced to capture the pairwise associations between user
and content features. The parametric model is optimized by
Ô¨Åtting the observed interactive feedback.
3.1 Bilinear Indicator

The bilinear models can be regarded as a special case in
the Tucker family [14], which have been widely applied in
machine learning applications. For example, Tenenbaum
and Freeman [39] developed a bilinear model for separat-
ing ‚Äústyle‚Äù and ‚Äúcontent‚Äù in images, and recently Chu and
Ghahramani [11] derived a probabilistic framework of the
Tucker family for modeling structural dependency from par-
tially observed high-dimensional array data.

We deÔ¨Åne an indicator as a bilinear function of xi and zj

in the following:

sij =

xi,bzj,awab,

(1)

C:a=1

D:b=1

where D and C are the dimensionality of user and content
features respectively, zj,a denotes the a-th feature of zj and
xi,b denotes the b-th feature of xi. The weight variable wab is
independent of user and content features and quantiÔ¨Åes the
aÔ¨Énity of these two factors xi,b and zj,a in interactions.2

The scalar sij is generated by mixing these basis vectors
with coeÔ¨Écients given by the Kronecker product of xi and
zj. The indicator can be equivalently rewritten as

sij = w

(cid:62)

(zj ‚äó xi),

1Clicks and user purchase history are often considered as im-
plicit feedback in other collaborative Ô¨Åltering literature since
these may not reÔ¨Çect real user preferences. For example, a
user may Ô¨Ånd that an article is uninteresting after clicking
and reading it. However, we refer these actions as explicit
feedback since the user intentions of these actions are clearer
than those of other implicit feedback such as linger time and
eye movement.
2In practice, we also insert an individual-speciÔ¨Åc oÔ¨Äset for

WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems693where w is a column vector of entries {wab}, and zj ‚äó xi
denotes the Kronecker product of xi and zj, a column vector
of entries {xi,bzj,a}. In matrix form, eq(1) can be rewritten
as

sij = x

(cid:62)
i W zj,

(cid:62)

(2)

(cid:62)
i,dzj,d,

(cid:62)
i Ws, x

a=1 Àúxi,azj,a.

(cid:62)
i,szj,s + Àúx

zj,d  = Àúx

where W denotes a D√ó C matrix with entries {wab}, which
describes a linear projection from the user feature space onto
the item feature space. The projected user proÔ¨Åle W(cid:62)xi
is aligned to the item features, denoted by Àúxi, which can
be explained as users‚Äô preferences on item characteristics
accordingly. Then the indicator becomes a dot product, i.e.
sij = Àúx(cid:62)

To further examine the feature functions, let us distin-
guish dynamic features in the item feature vector as zj =

i zj =2C
 zj,s
zj,d , where zj,s denotes static features and zj,d denotes
sij =Dx

dynamic features that vary along time. The indicator sij
can then be rewritten as follows,

i WdE zj,s

where Ws and Wd denote the columns in W associated
with the static and dynamic item features respectively, and
Àúxi,s and Àúxi,d denote the i-th user‚Äôs preferences on the static
and dynamic item features respectively.
Note that a user‚Äôs score sij on an item is composed of
three parts: Àúx(cid:62)
i,szj,s reÔ¨Çects long-term personal preferences
on content features learnt from historical activities; zj,d is
of dynamic characteristics, in our work which include tem-
poral popularity over the whole user population, i.e. article
quality; the tradeoÔ¨Ä between static personal preferences and
article quality is determined by Àúxi,d.
On cold-start with new items, the user‚Äôs preferences on
static item features Àúx(cid:62)
i,szj,s play an important role, as the
dynamic features couldn‚Äôt be accurately estimated at the
beginning stage. Similarly, on cold-start with new users,
recommendations are fully determined by the users‚Äô pref-
erences on content features Àúxi, which are projected from
the user proÔ¨Åle xi.3 As we will show in the following, the
projection W can be learnt from the historical interactive
feedback.
3.2 Probabilistic Framework

We employ appropriate likelihood functions to relate the

indicator sij to diÔ¨Äerent types of observed interactions.

‚Ä¢ Continuous scores with Gaussian measurement noise:

p(rij|sij) =

1‚àö
2œÄœÉ

exp‚àí (rij ‚àí sij)2

2œÉ2

 ,

where œÉ stands for the noise level.4
each user. The Ô¨Ånal scalar is evaluated as

sij =

C:a=1

D:b=1

where ¬µi ‚àà 4 denotes a user-speciÔ¨Åc oÔ¨Äset. Here ¬µi is used to

tradeoÔ¨Ä the user‚Äôs activity level, since some users are active
clickers while some are casual users.
3There is an implicit assumption that the user proÔ¨Åle is rich
enough to be transformed into preferences on item charac-
teristics. This condition can be easily satisÔ¨Åed in practice.
4In practice, the noise level could be preÔ¨Åxed at an appro-
priate value based on the signal/noise ratio.

xi,bzj,awab + ¬µi,

‚àÇL(w)
‚àÇwab

=

‚àÇ log p(rij|sij)

‚àÇsij

xi,bzj,a,

(7)

‚Ä¢ Binary actions with rij ‚àà {‚àí1, 1}. The logistic func-
tion is widely used as the likelihood function, which is
deÔ¨Åned as

p(rij|sij) =

1

1 + exp(‚àírijsij + Œ≥)

,

where Œ≥ denotes a bias term, usually set at 1.

Given a set of w, the likelihood of observing the interac-

tive data can be evaluated by

p(rij|sij),

(3)

p(|w) =;ij

(4)

(5)

where the index ij runs over the observational set .
weight variables as a priori,

We also specify a standard Gaussian distribution over the

p(w) =

1‚àö
2œÄœÇ

where œÇ 2 is the variance.

exp‚àí2ab w2
2œÇ 2  ,

ab

Based on the Bayes‚Äô theorem, the posterior distribution
of w is proportional to the product of the likelihood and the
prior,

where p(w) is the prior distribution deÔ¨Åned as in eq(4) and

p(w|) ‚àù p(|w) p(w).
p(|w) is the likelihood deÔ¨Åned as in eq(3).
3.3 OfÔ¨Çine Modeling

In this section, we describe a training algorithm in batch
mode to estimate the posterior distribution of the weight

coeÔ¨Écients p(w|) as in eq(5). For continuous scores with

Gaussian noise, the posterior distribution is still a Gaussian
due to the conjugate property. With non-Gaussian like-
lihood functions, the posterior distribution becomes non-
Gaussian. However we can always approximate the true
distribution by a Gaussian distribution. One of the most
popular techniques is the Laplace approximation [26], which
Ô¨Ånds the mode of the true posterior as the approximate mean
and approximates the inverse covariance matrix by the Hes-
sian matrix, the second order derivatives with respect to the
weights at the mode point.

The mode, also known as the maximum-a-posteriori (MAP)

estimate, can be found by maximizing the joint probabil-

ity p(|w)p(w). The optimization problem is equivalent to

minimizing the negative logarithm of the joint probability,
i.e.

min

w

L(w) =

log p(rij|sij),

(6)

where œÇ 2 plays a role of tradeoÔ¨Ä. The gradient with respect
to wab can be computed as follows,

w2

ab ‚àí:ij

1

2œÇ 2:ab
œÇ 2 ‚àí:ij

wab

and gradient-decent packages can then be employed to Ô¨Ånd
the minimum. Note that the objective functional is convex
and the minimum is unique. The detailed formulations are
given in Table 1 and the gradient-descent algorithm is sum-
marized as in Table 2. Each objective/gradient evaluation
costs O(N CD), where CD is the size of w and N is the
size of the observed set . Note that matrix inverse can

WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems694Table 1: The logarithm likelihood functions and the
Ô¨Årst-order derivatives.
‚àÇ log p(rij|sij )

log p(rij|sij)

Target

Continuous

Binary

‚àí (rij‚àísij )2
2 log(2œÄœÉ)
‚àí log(1 + exp(‚àírijsij + Œ≥))

‚àí 1

2œÉ2

‚àÇsij
sij‚àírij

œÉ2

rijp(‚àírij|sij)

Table 2: The gradient-descent algorithm for MAP.
1.
2. While objective/gradient evaluation at w is requested:

Initialize w = 0, given œÉ2 and œÇ 2

Compute the objective as in eq(6);
Compute the gradients for w as in eq(7);
Return the objective/gradients to the package.

3. Until the optimization package returns the Ô¨Ånal w.

be applied directly to the case of continuous targets for an
solution, but the computational cost is O(N C 2D2 + C 3D3).
It is very expensive for the cases having a large number of
features.
3.4 Prediction

The MAP estimate, denoted as wMAP, is then applied to
new user/item pairs for prediction. For any pair of xi and
zj in test, the best guess of the indicator sij is determined
as follow,

ÀÜsij =

xi,bzj,awMAP

ab

,

(8)

C:a=1

D:b=1

is an entry of the MAP estimate wMAP.

ab

where wMAP
3.5 Discussions

In this section, we discuss model selection and some poten-
tials of the framework we proposed, such as online learning
and active learning.

3.5.1 Model Selection

The prior variance œÇ 2 is an important model parameter in
the regression framework. The most common approach in
practice to determine the best model setting is cross valida-
tion. In k-fold cross validation, the original training data is
randomly partitioned into several folds, whereas in our ap-
plication having time series of dynamical features we have
to split the training data by a temporal point into two folds,
usually with size ratio 2 : 1. Given a particular set of model
parameters, we run the training algorithm on the fold of
earlier data to estimate the weight coeÔ¨Écients, and test the
resulting model on the left-out fold to obtain the validation
error. The predictive performance indicates the goodness
of the model parameter setting. We try grid search over a
set of parameter values to Ô¨Ånd the optimal one on which we
observe the best performance on the validation data. The
optimal weight coeÔ¨Écients in the regression model are Ô¨Å-
nally obtained by training on the whole training data set
using the best set of model parameters.

3.5.2 Online Learning and Active Learning

In this work we only focus on training an oÔ¨Ñine model cou-
pled with dynamic features, whereas the probabilistic frame-
work we employed provides the capacity of online learning
as well. Assumed-density Ô¨Åltering (ADF) is a one-pass, se-
quential method for computing an approximate posterior

distribution [17].
In ADF, observations are processed one
by one, updating the posterior distribution which is usually
approximated as a Gaussian before processing the next ob-
servation. The approximate posterior is found by minimiz-
ing KL-divergence to preserve a speciÔ¨Åc set of posterior ex-
pectations. Recently, Expectation Propagation [29] extends
ADF to incorporate iterative reÔ¨Ånement of the approxima-
tions, which iterates additional passes over the observations
and does not require corresponding with time of arrival as
in time series.

Learning could be made more eÔ¨Écient if we can actively
select salient data points. Within the probabilistic regres-
sion framework, the expected informativeness of a new ob-
servation can be measured by the change in entropy of the
posterior distribution of the weight coeÔ¨Écients after inclu-
sion of the candidate [24]. The new posterior distribution
with the inclusion of the unused sample can be approx-
imated as a Gaussian by ADF-like online learning algo-
rithms. Based on information-theoretical principles, the en-
tropy gain on the posterior distribution of weight variables
can then be applied as the criterion for candidate election.

4. RELATED WORK

Our work is closely related to adaptive news systems, one
of the most popular types of personalized Web-based service
[6]. The most relevant previous work to our study would
be the Google News recommender system [15], a content-
agnostic system which combines three diÔ¨Äerent algorithms
using a linear model to generate recommendations in News
domain. However, since the proposed approach is a pure
collaborative Ô¨Åltering, it does not solve the cold-start prob-
lem for new users. Even though ratings from new users can
be updated in near real-time by gridifying their algorithm,
it still needs to wait until new users provide ratings or clicks
before making recommendations. Also, the reported results
are based on two heavy user data sets (top 5K heavy users
with 370K clicks and 500K users with 10M clicks), where
eÔ¨Äects of new and casual users haven‚Äôt been considered. In
our application of the Today-Module on Yahoo! Front Page,
40% of clickers are new clickers with no historical clicks, 82%
of clickers have less or equal to 5 historical clicks, 92% of
clickers have no more than 10 historical clicks as shown in
the Figure 3(b). Another key diÔ¨Äerence lies in that Google
News [15] is a content-agnostic system which doesn‚Äôt resort
to either content features or user information. YourNews
[2] allows users to customize their interest proÔ¨Åles through
a user model interface. The study on user behavior shows
the beneÔ¨Åt from customization but also cautions the down-
side on system performance. In our application, we build up
user and content proÔ¨Åles without any solicitation on users.
Newsjunkie [18] provided personalized news feeds for users
by measuring news novelty in the context of stories the users
have already read. Our content proÔ¨Åles can also maintain
dynamic features in addition to context novelty, such as pop-
ularity and freshness. Our model also leverages user proÔ¨Åles
to facilitate cold-start on new users.

Our work is also related to personalized search, though
the tasks are quite diÔ¨Äerent. Micarelli et al. [28] gave a nice
review on this direction. Personalized search builds models
of short-term and long-term user needs based on observed
user actions, which is able to satisfy the users better than
standard search engines based on traditional Information
Retrieval (IR) techniques. Speretta and Gauch [38] devel-

WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems695oped user proÔ¨Åles from their query histories and used these
proÔ¨Åles to re-rank the results returned by an independent
search engine by giving more importance to the documents
related to topics contained in the user proÔ¨Åle. Ahn et al.
[2] designed the TaskSieve system that utilizes a relevance
feedback-based proÔ¨Åle for personalized search. Both systems
employ the traditional linear approach to combine personal
preferences and query relevance. The combined score is cal-
culated as Œ±f (xi, zj)+(1‚àíŒ±) r(zj), where xi is a user proÔ¨Åle,
zj is a content item fused with the query and Œ± is the trade-
oÔ¨Ä. There is a strong correspondence to the terms in eq(2).
By replacing the dynamic features of zj by the query rele-
vance r(zj) and implement f (xi, zj) in the parametric form
of the long-term preferences as in eq(2), our bilinear model
provides a Ô¨Çexible framework to learn the personal prefer-
ence function and the tradeoÔ¨Ä term from the click stream in
a principled manner.

A personalized service may not be exactly based on in-
dividual user behaviors. The content of a website can be
tailored for a predeÔ¨Åned audience, based on oÔ¨Ñine research
of conjoint analysis, without online gathering knowledge on
individuals for service. Conjoint analysis is one of the most
popular market research methodologies for assessing how
customers with heterogeneous preferences appraise various
objective characteristics in products or services. Analysis
of tradeoÔ¨Äs driven by heterogeneous preferences on bene-
Ô¨Åts derived from product attributes provides critical inputs
for many marketing decisions, e.g. optimal design of new
products, target market selection, and pricing a product. In
very early studies [40], homogeneous groups of consumers
are entailed by the use of a priori segmentation. For ex-
ample, consumers are assigned to groups on the basis of
demographic and socioeconomic variables, and the conjoint
models are estimated within each of those groups. This is
closely related to demographic recommender systems [23,
34], in which recommendations are based on demographic
classes categorized by users‚Äô personal attributes. However,
the criteria in the two steps are not necessarily related: one
is the homogeneity of customers in terms of their descrip-
tor variables and another is the conjoint preferences within
segments. Traditionally, conjoint analysis procedures are of
two-stage: 1) estimating a parametric function which rep-
resents customers‚Äô preference at individual-level in terms of
user proÔ¨Åles, e.g. hierarchical Bayesian methods [25]; 2)
through clustering algorithms, grouping users into segments
where users share similar individual-level preferences. Jiang
and Tuzhilin [22] experimentally demonstrated both 1-to-
1 personalization and segmentation approaches signiÔ¨Åcantly
outperform aggregate modeling.

In the extreme cold-start setting with dynamic content
and a large amount of new users, traditional collaborative Ô¨Ål-
tering methods cannot provide recommendation eÔ¨Äectively.
A number of hybrid methods, which combine information
Ô¨Åltering and other collaborative Ô¨Åltering techniques, have
been proposed, such as [12] of an online newspaper and the
Fab system [3]. Good et al.
[20] improved accuracy by
introducing personal agents, and Park et al.
[33] further
improved its performance in cold-start situations by adding
small number of artiÔ¨Åcial users who have rated all items.
However, this approach performs better only if a user has
rated a few items but does not solve the cold-start problem
[5] utilized social infor-
directly for new users. Basu et al.
mation in content-based Ô¨Åltering. Melville et al.
[27] em-

Figure 2: A snapshot of the default ‚ÄúFeatured‚Äù tab
in the Today Module on Yahoo! Front Page. There
are four articles displayed at footer positions. One of
the four articles is highlighted at the story position.

ployed a content-based predictor to enhance existing user
data, and then provided personalized suggestions through
collaborative Ô¨Åltering. Basilico and Hofmann [4] developed
a framework that incorporates all available information by
using a suitable kernel or similarity function between user-
item pairs. Hybrid methods are especially useful when data
is sparse, for example in cold-start situations [35], but to
our best knowledge none of previous work has been inte-
grated with continuous online attributes, such as popularity
or freshness.

5. CASE STUDIES

In this section, we verify the capacity of the proposed bi-
linear models on a real-world application. We start with
an introduction of the problem settings in Yahoo! Today-
Module and describe the attributes we collected in user/content
proÔ¨Åling. We also deÔ¨Åne performance metrics to evaluate
predictive results and report experimental results with com-
parison to competitive approaches.
5.1 Yahoo! Today Module

Today-Module is the most prominent panel on Yahoo!
Front Page, which is also one of the most visited pages on the
Internet, see a snapshot in Figure 2. The default ‚ÄúFeatured‚Äù
tab in Today Module highlights one of four high-quality ar-
ticles, mainly news, while the four articles are selected from
a daily-refreshed article pool curated by human editors. As
illustrated in Figure 2, there are four articles at footer po-
sitions, indexed by F1, F2, F3 and F4 respectively. Each
article is represented by a small picture and a title. One of
the four articles is highlighted at the story position, which
is featured by a large picture, a title and a short summary
along with related links. At default, the article at F1 is
highlighted at the story position. A user can click on the
highlighted article at the story position to read more details
if she is interested in the article. The event is recorded as
a story click. If a user is interested in an article at F2‚àºF4
positions, she can highlight the article at the story position
by clicking on the footer position. To draw visitors‚Äô atten-
tion, we would like to rank available articles according to
visitors‚Äô interests, and highlight the most attractive article
at F1 position.

It is diÔ¨Écult to adopt a traditional collaborative Ô¨Ålter-
ing algorithm such as user-user [7] or item-based [16] in the

WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems696Today-Module. Retrieving historical ratings of users for sim-
ilarity evaluation in the online service is hard. Lifetime of an
article is very short (only a few hours) and old articles will
be pulled out of content pool regularly. Another diÔ¨Éculty is
that we always need to recommend new items and signiÔ¨Åcant
portion of users is taken by new users. As shown in Figure
3(b) and (c), 40% clickers in the test data are the Ô¨Årst time
clickers without any historical clicks, and on average 60%
articles are new everyday. Thus, traditional collaborative
Ô¨Åltering methods suÔ¨Äer from the cold-start problem. Fur-
thermore, the article popularity is temporally decaying, see
Figure 3(a) for an example where CTR decreases to 1/6 of
its peak value at the end of the article‚Äôs lifetime. It is diÔ¨É-
cult to compare users‚Äô feedback on the same article received
at diÔ¨Äerent time slots.
5.2 Data Collection

We collected events from a random bucket in July 2008.
In the random bucket, articles are randomly selected from
the content pool to serve users. An event records a user‚Äôs
action on the article at the story position, which is either
‚Äúview‚Äù or ‚Äúclick‚Äù encoded as ‚àí1 and 1 respectively. Note
that a user may click on the same article multiple times
but at diÔ¨Äerent time slots.5 In our approach, these binary
events are distinguishable, because a content item is deÔ¨Åned
by both the article and the time slot of the event of interest,
see Figure 1. This is a conceptual diÔ¨Äerence from traditional
approaches.

We collected about 40 million click/view events by about
5 million users from the random bucket before a certain time
stamp for training. We also collected about 0.6 million click
events after that time stamp for test.

The features of users and items were selected by ‚Äúsupport‚Äù.
The ‚Äúsupport‚Äù of a feature means the number of users hav-
ing the feature. We only selected the features of high sup-
port above a preÔ¨Åxed threshold, e.g. 10% of the population.
Then each user is represented by a vector of more than one
thousand categorical features, which include:

‚Ä¢ Demographic information: gender (2 classes) and age

discretized into ten classes;

‚Ä¢ Geographic features: about two hundred locations of

countries or U.S. States;

‚Ä¢ Behavioral categories: about one thousand binary cat-
egories that summarize the user‚Äôs consumption behav-
ior within Yahoo! properties;

Each article is proÔ¨Åled by a vector of about one hundred
static features and a dynamic feature. The static features
include:

‚Ä¢ URL categories: tens of classes inferred from the URL

of the article resource;

‚Ä¢ Editor categories: tens of topics tagged by human ed-

itors to summarize the article content;

The dynamic feature is of estimated click-through rate (CTR)
at events of interest, which diÔ¨Äerentiates the same article at
diÔ¨Äerent time slots. We adapted the Kalman Ô¨Ålter designed

5For anti-robot purpose, the number of clicks generated by
one user on the same article could be at most 1 within a
single time slot (e.g. 5 minutes).

Figure 3: (a) A typical pattern of article CTR; (b)
Historical click counts of clickers in test; (c) New
article percentage per day in test.

and implemented by our team [1] for CTR tracking, which
yields a good indicator of article quality and popularity tem-
porally. Note that other dynamic features, e.g.
freshness,
can be added into the content proÔ¨Åles as well.

‚àö

Categorical features are encoded as binary vectors with
non-zero indicators. For example, ‚Äúgender‚Äù of two classes is
translated into two binary features, i.e., ‚Äúmale‚Äù is encoded as
[0, 1], ‚Äúfemale‚Äù is encoded as [1, 0] and ‚Äúunknown‚Äù is [0, 0].6
As the number of non-zero entries in these binary feature
vectors varies, we further normalized each vector into unit
length, i.e., non-zero entries in the normalized vector are
replaced by 1/
k, where k is the number of non-zero en-
tries. For user features, we normalized behavioral categories
and the remaining features (age, gender and location) sepa-
rately, due to the variable length of behavioral categories per
user. For article features, we normalized URL and Editor
categories together, and kept the CTR term (a real value) in-
tact. Following conventional treatment, we also augmented
each feature vector by a constant term 1. Each content item
is represented by a feature vector of 83 entries, while each
user is represented by a feature vector of 1193 entries.
5.3 Performance Metric

For each user in test, we computed predictive scores as in
eq(8) for all available articles at the time stamp of the event,
and ranked these articles in descending order according to
the scores. On click events, we measured the rank position
of the article being clicked by the user.

The Ô¨Årst metric we use is the number of clicks in each rank
position. A good predictive model should have more clicks
on the top-ranked positions and lesser clicks on the lower-
ranked position. In our application, we mainly concern the
performance on the top 4 positions.

We also proposed a simple utility function to quantify the

predictive performance, which is deÔ¨Åned as follows:

4:r=1

6The ‚Äúunknown‚Äù category coded with zero entries has little
contribution to our linear models.

U =

Ur
2r‚àí1 ,

(9)

20406080100120140160180Time Index (5 Minutes)CTR01 2 3 4 5 6 7 8 9 1000.10.20.30.40.5Number of ClicksNumber of Users (%)12345678900.20.40.60.8Time Index (One Day)New Articles (%)(a) (b) (c) WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems697where Ur denotes the percentage of clicks at the rank posi-
tion r in the whole test clicks.

5.4 Competitive Approaches

We implemented three sets of competitive approaches for

comparison purpose.

5.4.1 Aggregate Level (EMP)

As a baseline, we aggregated clicks and views per article
along time over the whole population, and ranked articles
by the global CTR only. The CTR online tracking was im-
plemented with the Kalman Ô¨Ålter designed in [1], which has
yielded very strong performance in the product. In this ap-
proach, denoted by EMP, users are served with the same
content (the estimated most popular article) at the same
time stamp.

5.4.2

Segmentation Level (GM and SEG5)

Presupposing the existence of heterogeneity in users‚Äô pref-
erences on articles, we carried out two conjoint analysis
methods on the Today-Module data: a) GM: We simply
grouped users into 6 clusters based on rules of their demo-
graphic variables (age and gender); b) SEG5: We estimated
users‚Äô preferences on article features Ô¨Årst following the hier-
archical Bayes approach discussed by [25] and then clustered
homogeneous users with similar preferences by K-means.7
At segmentation level, we aggregated clicks and views per
article within user segments, and estimated the article CTR
within segments. A user will be served with the most popu-
lar article in the segment she belongs to. The CTR estima-
tion within segments suÔ¨Äers from low-traÔ¨Éc issues when the
number of segments is large. On this application, we tried
2, 5, 10 and 20 segments and found the performance of 5
segments is the best out of the four settings.

At both aggregate and segmentation level, we applied the
same online CTR tracking technique [1], which was also used
for updating the dynamic feature of article CTR at aggregate
level in content proÔ¨Åles.

5.4.3 Individual Level (IBCF, CB and CB+EMP)

We implemented three alternative individual level approaches

to compare against our bilinear models.

Item-based collaborative Ô¨Åltering (IBCF).

We implemented a standard item-based collaborative Ô¨Ål-
tering algorithm as in [16]. We update the item-item simi-
larity matrix in every hour by calculating cosine similarity of
two articles in the user click behaviors. When the algorithm
cannot recommend anything due to lack of user information
(i.e. new users), the algorithm rank candidate articles based
on the aggregate CTR.

Content-based Ô¨Åltering (CB).

As we discussed in Section 5.2, each user xi and item
zj can be represented as a vector of categorical features
(without dynamic features) as xi = {xi,1, .., xi,D} and zj =
{zj,1, .., zj,C} respectively. We normalized user and item vec-
k=1 zj,k = 1.

tors into unit sum, i.e. 2D

k=1 xi,k = 1 and2C

7Monte Carlo sampling methods suggested in [25] cannot
be applied to our application. We resorted to the MAP
estimate via gradient descent methods. More details of seg-
mentation analysis will be reported in another paper.

For each vector, xi,k = 1|xi|
if the user has the k-th user-
feature and xi,k = 0 otherwise, where |xi| denotes the num-
ber of non-zero features in xi.

We maintained two aÔ¨Énity matrices between heteroge-
neous features for click and view events respectively. For a
click/view event of xi and zj, the click/view aÔ¨Énity between
the b-th user-feature and the a-th item-feature is accumu-
lated with xi,bzj,a. Note that the total contribution from a
single event is always one. For each pair of heterogeneous
features, we aggregated the contributions over all click/view
events in the training samples, and then calculated the aÔ¨Én-
ity ratio between click and view, denoted as œÖab.

After we learnt the aÔ¨Énities for all feature pairs, the pref-
erence score given by a user xi on an item zj is calculated as
b=1 xi,bzj,aœÖab which is analogous to our bilin-
ear model in eq(1) but is of diÔ¨Äerent feature normalization
and aÔ¨Énity estimation.

cij =2C

a=12D

CB with online CTR (CB+EMP).

Since the estimated CTR of an item at time t, denoted
by CT Rj,t, provides tremendous insight on the quality of
the item at time t, we followed the hybrid approaches [10]
to combine CTR with the score from the content-based ap-
proach. Motivated by the combinations proposed in person-
alized search [38, 2], the Ô¨Ånal score given by a user xi on an
item zj at time t was evaluated by (1 ‚àí Œ±) cij + Œ± CT Rj,t
where CT Rj,t denotes CTR of the article zj at time t, and
0 ‚â§ Œ± ‚â§ 1 is a trade-oÔ¨Ä parameter determined by cross vali-
dation. We found Œ± = 0.8 yields the best validation results.
5.5 Results

We implemented two versions of the probabilistic bilin-
ear models. One treated the feedback as continuous scores
(RG), whereas another took the click-or-not events as bi-
nary targets (LRG). We employed a gradient-descent pack-
age for the MAP estimate in the posterior distribution of the
weights as described in Section 3.3. The model parameter
œÇ 2 was determined by cross validation on [0.01, 0.1, 1, 10], as
discussed in Section 3.5.1. For each user in test, we com-
puted the expected score ÀÜsij as in eq(8) for all available
articles at the event, and ranked these articles in descending
order according to the scores.

In Table 3, we presented the portions of clicks at the top
16 rank positions of all the methods we have implemented
and computed the utility function deÔ¨Åned as in eq(9). We
also carried out Wilcoxon rank sum tests on the predicted
click ranks to evaluate the signiÔ¨Åcance of the diÔ¨Äerence be-
tween the LRG‚Äôs ranks and other methods‚Äô predictions, and
reported the p-values in Table 3. A p-value close to zero
means the two predictive results are signiÔ¨Åcantly diÔ¨Äerent,
while near 1 means the diÔ¨Äerence is not signiÔ¨Åcant. Usually
we set the level of signiÔ¨Åcance at 0.05. LRG greatly out-
performs other methods on both click portions on the top
4 positions and the utility function. The hypothesis testing
results also show the improvement is signiÔ¨Åcant over all com-
petitors. GM, a rule-based segmentation, doesn‚Äôt result in
much improvement, compared with SEG5 that fuses proÔ¨Åles
and feedback for user segmentation.

CB relying on user/item static features only recommends
items similar to what a user has already rated, but it is hard
to capture new features that the user might like and to pro-
vide serendipity Ô¨Ånding which collaborative Ô¨Åltering can do.
CB+EMP, a combined approach, performs slightly better

WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems6981
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

EMP
12.47%
9.93%
8.80%
8.00%
7.24%
6.85%
6.51%
6.08%
5.60%
5.20%
4.86%
4.46%
4.08%
3.60%
3.18%
2.82%

12.52%
10.06%
8.81%
7.99%
7.29%
6.83%
9.47%
6.03%
5.60%
5.17%
4.78%
4.43%
4.02%
3.57%
3.17%
2.9%

CB

IBCF

SEG5
13.08% 10.01% 8.09%
8.46% 7.87%
10.43%
7.80% 7.32%
9.02%
7.41% 7.34%
8.18%
7.39%
6.72% 6.74%
6.52% 6.63%
6.92%
6.56% 6.52%
6.40%
6.18% 6.12%
5.87%
5.58%
5.81% 6.13%
5.68% 6.41%
5.06%
5.29% 5.82%
4.67%
5.06% 5.22%
4.27%
4.89% 4.75%
3.82%
3.35%
4.73% 5.11%
4.21% 4.75%
2.99%
2.63%
4.15% 4.59%
2.41e-24
0.2157

0.1712

0.1477

12.49%
9.92%
8.81%
7.98%
7.26%
6.88%
6.47%
6.07%
5.68%
5.24%
4.75%
4.45%
4.04%
3.62%
3.18%
2.79%
3-e201
0.2065

9.08%
8.70%
8.15%
7.67%
7.29%
6.92%
6.58%
6.22%
5.84%
5.63%
5.38%
4.98%
4.48%
4.35%
4.18%
4.02%

0

0.1642

13.34% 13.45%
10.57% 10.60%
9.23%
9.28%
8.21%
8.28%
7.56%
7.5%
6.85%
6.98%
6.34%
6.40%
5.84%
5.90%
5.49%
5.37%
4.98%
4.98%
4.56%
4.55%
4.22%
4.16%
3.81%
3.74%
3.22%
3.32%
2.93%
2.85%
2.41%
2.47%
0.1022
0.2198

0.2209

1

Table 3: Click portions on predictive rank positions, along with Ranksum Test and Utility results.
LRG

LRG-CTR

CB+EMP

Rank Position

GM

RG

Ranksum Test

7.109e-212

1.145e-182

Utility

0.2063

0.2075

0

0

6. CONCLUSIONS

We proposed a feature-based bilinear regression frame-
work for personalized recommendation on dynamic content.
We quantiÔ¨Åed associations between attributes in user pro-
Ô¨Åles and content proÔ¨Åles through learning a parametric bi-
linear regression function from interactive feedback. This
approach results in an oÔ¨Ñine model but with the dynamic
features in content proÔ¨Åles, which provides the capacity of
recommending new high-quality content promptly and accu-
rately. In contrast to traditional recommender systems, our
approach also greatly alleviates the cold-start issue of rec-
ommending for new users, by leveraging interest patterns
in user proÔ¨Åles recognized from regression over historical in-
teractive feedback. We found the personalized predictive
models signiÔ¨Åcantly outperform six competitive approaches
at aggregate, segmentation or individual levels on the appli-
cation of Yahoo! Front Page Today-Module.

The potentials of the probabilistic bilinear regression frame-

work haven‚Äôt been fully exploited. It is straightforward to
implement online learning algorithms within the proposed
regression framework, which may be useful in tracing users‚Äô
short-term interests. Based on information-theoretical prin-
ciples, eÔ¨Écient learning could be achieved by actively elect-
ing salient samples. The techniques we proposed for dy-
namic content can be adapted for personalized search as
well. We plan to investigate these directions in future work.

7. ACKNOWLEDGMENTS

We thank Raghu Ramakrishnan, Scott Roy, Deepak Agar-
wal, Bee-Chung Chen, Pradheep Elango, and Ajoy Sojan for
many discussions and helps on data collection.

8. REFERENCES
[1] D. Agarwal, B. Chen, P. Elango, N. Motgi, S. Park,

R. Ramakrishnan, S. Roy, and J. Zachariah. Online models
for content optimization. In Advances in Neural
Information Processing Systems 21, 2009.

[2] J. Ahn, P. Brusilovsky, J. Grady, D. He, and S. Y. Syn.

Open user proÔ¨Åles for adaptive news systems: help or

Figure 4: Lift over EMP (the baseline at aggregate
level) on click portion at the top 4 positions.

than EMP, but the improvement gained from the weighted
sum is insigniÔ¨Åcant. Traditional item-based collaborative
Ô¨Åltering (IBCF) performs worse than EMP since the great
portion of users in our dataset are new or casual users who
do not click much. Note that 92% of clickers in our test
data have clicked no more than 10 articles, while Google
News [15] and other collaborative Ô¨Åltering literatures only
consider a group of heavy users who have rated at least 20
items, often more than 100 items. We also measured the
performance of LRG after removing the dynamic CTR fea-
ture (LRG-CTR) to see its impact on performance. As seen
in the Table 3, removing the dynamic feature causes signif-
icant performance degradation that shows the CTR feature
is a crucial part in our application.

We presented the portion lift at the top 4 positions in
Figure 4. SEG5 also yields about 5% lift over the EMP
approach, and LRG gives 8% lift. RG also performs well but
is worse than LRG, as shown in Table 3. On this application
with click-or-not feedback, it is prudent to apply LRG on the
binary targets.

 	
WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems699harm? In Proceedings of the International World Wide
Web Conference, 2007.

[3] M. Balabanovic and Y. Shohan. Fab: Content-based,

collaborative recommendation. Communications of the
ACM, 40, 1997.

American Association of ArtiÔ¨Åcial Intelligence, pages
439‚Äì446, 1999.

[21] R. Guttman, A. Moukas, and P. Maes. Agent-mediated
electronic commerce: A survey. Knowledge Engineering
Review, 13(3), June 1998.

[4] J. Basilico and T. Hofmann. A joint framework for

[22] T. Jiang and A. Tuzhilin. Segmenting customers from

collaborative and content Ô¨Åltering. In Proceedings of the
International ACM SIGIR Conference, 2004.

[5] C. Basu, H. Hirsh, and W. W. Cohen. Recommendation as
classiÔ¨Åcation: Using social and content-based information in
recommendation. In Proceedings of the Fifteenth National
Conference on ArtiÔ¨Åcial Intelligence, pages 714‚Äì720, 1998.

[6] D. Billsus and M. Pazzani. Adaptive news access. In
P. Brusilovsky, A. Kobsa, and W. Nejdl, editors, The
Adaptive Web ‚Äî Methods and Strategies of Web
Personalization, volume 4321 of Lecture Notes in
Computer Science. Springer Berlin / Heidelberg, 2007.

[7] J. S. Breese, D. Heckerman, and C. Kadie. Empirical

analysis of predictive algorithms for collaborative Ô¨Åltering.
In Proceedings of the Conference on Uncertainty in
ArtiÔ¨Åcial Intelligence, pages 43‚Äì52, 1998.

[8] P. Brusilovsky, A. Kobsa, and W. Nejdl, editors. The

Adaptive Web ‚Äî Methods and Strategies of Web
Personalization, volume 4321 of Lecture Notes in
Computer Science. Springer Berlin / Heidelberg, 2007.

[9] A. G. B¬®uchner, J. G. Hughes, and D. A. Bell. Contextual

data and domain knowledge for incorporation in knowledge
discovery systems. In J. Wang, editor, Modeling and Using
Context, volume 1688, pages 831‚Äì832, 1999.

[10] R. Burke. Hybrid systems for personalized

recommendations. In B. Mobasher and S. S. Anand,
editors, Intelligent Techniques for Web Personalization.
Springer-Verlag, 2005.

[11] W. Chu and Z. Ghahramani. Probabilistic models for

incomplete multi-dimensional arrays. In Proceedings of the
12th International Conference on ArtiÔ¨Åcial Intelligence
and Statistics, 2009.

[12] M. Claypool, A. Gokhale, T. Miranda, P. Murnikov,

D. Netes, and M. Sartin. Combining content-based and
collaborative Ô¨Ålters in an online newspaper. In ACM SIGIR
Workshop on Recommender Systems, 1999.

[13] M. Claypool, P. Le, M. Wased, and D. Brown. Implicit

interest indicators. In the 6th International Conference on
Intelligent User Interfaces. ACM Press, 2002.

[14] R. Coppi and S. Bolasco, editors. Multiway data analysis.

North-Holland Publishing Co., Amsterdam, The
Netherlands, The Netherlands, 1989.

[15] A. Das, M. Datar, A. Garg, and S. Rajaram. Google news

personalization: scalable online collaborative Ô¨Åltering. In
Proceedings of the International World Wide Web
Conference, 2007.

[16] M. Deshpande and G. Karypis. Item-based top-n

recommendation algorithms. ACM Transactions on
Information Systems (TOIS), 22(1):143‚Äì177, Jan 2004.

[17] B. J. Frey, R. Patrascu, T. Jaakkola, and J. Moran.

Sequentially Ô¨Åtting inclusive trees for inference in noisy-or
networks. In Advances in Neural Information Processing
Systems 13. MIT Press, 2000.

[18] E. Gabrilovich, S. Dumais, and E. Horvitz. Newsjunkie:

providing personalized newsfeeds via analysis of
information novelty. In Proceedings of the International
World Wide Web Conference, 2004.

[19] S. Gauch, M. Speratta, A. Chandranouli, and A. Micarelli.

User proÔ¨Åles for personalized information access. In
P. Brusilovsky, A. Kobsa, and W. Nejdl, editors, The
Adaptive Web ‚Äî Methods and Strategies of Web
Personalization. Springer Berlin / Heidelberg, 2007.

[20] N. Good, J. B. Schafer, J. A. Konstan, A. Borchers, B. M.

Sarwar, J. L. Herlocker, and J. Riedl. Combining
collaborative Ô¨Åltering with personal agents for better
recommendations. In Proceedings of the Conference of the

population to individuals: does 1-to-1 keep your customers
forever? IEEE Transactions on Knowledge and Data
Engineering, 18(10):1297‚Äì1311, 2006.

[23] B. Krulwich. Lifestyle Ô¨Ånder: Intelligent user proÔ¨Åling using

large-scale demographic data. ArtiÔ¨Åcial Intelligence
Magazine, 18(2):37‚Äì45, 1997.

[24] N. Lawrence, M. Seeger, and R. Herbrich. The informative

vector machine. In Advances in Neural Information
Processing Systems 15. MIT Press, 2003.

[25] P. J. Lenk, W. S. DeSardo, P. E. Green, and M. R. Young.
Hierarchical Bayes conjoint analysis: Recovery of partworth
heterogeneity from reduced experimental designs.
Marketing Science, 15(2):173‚Äì191, 1996.

[26] D. J. C. MacKay. The evidence framework applied to

classiÔ¨Åcation networks. Neural Computation, 4(5):720‚Äì736,
1992.

[27] P. Melville, R. Mooney, and R. Nagarajan. Content-boosted

collaborative Ô¨Åltering. In Proceedings of the Conference of
the American Association of ArtiÔ¨Åcial Intelligence, 2002.

[28] A. Micarelli, F. Gasparetti, F. Sciarrone, and S. Gauch.

Personalized search on the World Wide Web. In
P. Brusilovsky, A. Kobsa, and W. Nejdl, editors, The
Adaptive Web ‚Äî Methods and Strategies of Web
Personalization, volume 4321 of Lecture Notes in
Computer Science. Springer Berlin / Heidelberg, 2007.

[29] T. P. Minka. A family of algorithms for approximate

Bayesian inference. Ph.D. thesis, Massachusetts Institute
of Technology, January 2001.

[30] D. Mladenic. Text-learning and related intelligent agents:

A survey. IEEE Intelligent Agents, pages 44‚Äì54, 1999.

[31] B. Mobasher and S. S. Anand, editors. Intelligent

Techniques for Web Personalization, volume 3169 of
Lecture Notes in ArtiÔ¨Åcial Intelligence. Springer-Verlag,
2005.

[32] O. Nasraoui. World Wide Web personalization. In J. Wang,

editor, Encyclopedia of Data Warehousing and Mining,
pages 1235‚Äì1241. Idea Group, 2005.

[33] S.-T. Park, D. M. Pennock, O. Madani, N. Good, and

D. DeCoste. Na¬®ƒ±ve Ô¨Ålterbots for robust cold-start
recommendations. In Proceedings of the ACM SIGKDD
Conference on Knowledge Discovery and Data Mining,
2006.

[34] M. J. Pazzani. A framework for collaborative,

content-based and demographic Ô¨Åltering. ArtiÔ¨Åcial
Intelligence Review, 13, 1999.

[35] A. Popescul, L. Ungar, D. Pennock, and S. Lawrence.

Probabilistic models for uniÔ¨Åed collaborative and
content-based recommendation in sparse-data
environments. In Proceedings of the Conference on
Uncertainty in ArtiÔ¨Åcial Intelligence, pages 437‚Äì444, 2001.
[36] J. Saloj¬®arvi, K. Puolam¬®aki, and S. Kaski. Implicit relevance

feedback from eye movements. In Proceedings of the 15th
International Conference on ArtiÔ¨Åcial Neural Networks,
pages 513‚Äì518, 2005.

[37] J. B. Schafer, K. J., and J. Riedl. Recommender systems in

e-commerce. In Proceedings of the ACM Conference on
Electronic Commerce, 1999.

[38] M. Speretta and S. Gauch. Personalized search based on

user search histories. In Web Intelligence. IEEE Computer
Society, 2005.

[39] J. B. Tenenbaum and W. T. Freeman. Separating style and

content with bilinear models. Neural Computation,
12:1247‚Äì1283, 2000.

[40] Y. Wind. Issue and advances in segmentation research.

Journal of Marketing Research, 15:317‚Äì337, 1978.

WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems700