Characterizing Search Intent Diversity into Click Models

∗

Botao Hu1,2

, Yuchen Zhang1,2

∗

, Weizhu Chen2,3, Gang Wang2, Qiang Yang3

Institute for Interdisciplinary Information Sciences, Tsinghua University, China1

Microsoft Research Asia, Beijing, China2

Hong Kong University of Science and Technology, Hong Kong3

{botao.a.hu, zhangyuc}@gmail.com, {wzchen,gawa}@microsoft.com,

{wzchen,qyang}@cse.ust.hk

ABSTRACT
Modeling a user’s click-through behavior in click logs is a
challenging task due to the well-known position bias prob-
lem. Recent advances in click models have adopted the
examination hypothesis which distinguishes document rel-
evance from position bias.
In this paper, we revisit the
examination hypothesis and observe that user clicks can-
not be completely explained by relevance and position bias.
Speciﬁcally, users with diﬀerent search intents may submit
the same query to the search engine but expect diﬀerent
search results. Thus, there might be a bias between user
search intent and the query formulated by the user, which
can lead to the diversity in user clicks. This bias has not
been considered in previous works such as UBM, DBN and
CCM. In this paper, we propose a new intent hypothesis
as a complement to the examination hypothesis. This hy-
pothesis is used to characterize the bias between the user
search intent and the query in each search session. This hy-
pothesis is very general and can be applied to most of the
existing click models to improve their capacities in learn-
ing unbiased relevance. Experimental results demonstrate
that after adopting the intent hypothesis, click models can
better interpret user clicks and achieve a signiﬁcant NDCG
improvement.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Retrieval
Models

General Terms
Algorithm

Keywords
Click Model, Intent Bias, Intent Diversity, Search Engine,
User Behavior

1.

INTRODUCTION

Click-through logs record user activities on search pages
and encode user preferences of search results. Click-through
∗
crosoft Research Asia.

This work was done when the authors were interns at Mi-

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2011, March 28–April 1, 2011, Hyderabad, India.
ACM 978-1-4503-0632-4/11/03.

logs can be collected at a very low cost, and the analysis
of them can help to understand the user’s latest preference
tendencies. Naturally, many studies have attempted to dis-
cover user preferences from click-through logs to improve the
relevance of search results [12, 11, 1].

It is well known that clicks are “informative but biased”
[4], and it is a challenging task to estimate unbiased rel-
evance from click-through logs. One typical bias aﬀecting
user clicks is the so-called position bias: a document ap-
pearing in a higher position is more likely to attract user
clicks even though it is not as relevant as other documents
in lower positions. Thus, the click-through rate is not a
proper measure of relevance. This bias was ﬁrst noticed
by Granka et al.
[7] in their eye-tracking experiment and
some follow-up investigations have been made to alleviate
this bias so that the unbiased relevance can be inferred from
the clicks. Richardson et al.
[16] proposed to increase the
relevance of the documents in lower positions by using a
multiplicative factor. This idea was later formalized as the
examination hypothesis [4], which assumes that the user will
click a search result only after examining its search snippet.
In other words, given an examined document, only its rele-
vance determines the user click. The examination hypothesis
decouples document relevance from position bias where the
position bias is formulated as the probability that a doc-
ument is examined by a user. Recently, many interesting
studies have been made to reﬁne click models using the ex-
amination hypothesis. UBM[6], DBN[3], CCM[8], BBM[13],
GCM[19] are typical models which can extend the capabili-
ties of the examination hypothesis.

The examination hypothesis assumes that, if a document
has been examined, the click-through rate of the document
for a given query is a constant number whose value is de-
termined by the relevance between the query and the doc-
ument. We argue that users with diﬀerent search intents,
however, may submit the same query to the search engine.
In other words, a single query may not truly reﬂect user
search intent. Take the query “iPad” as an example. A user
submits this query because she wants to browse general in-
formation about iPad, and the results from apple.com or
wikipedia.com are attractive to her. In contrast, another
user who submits the same query may look for information
such as user reviews or feedback on iPad. In this situation,
search results like technical reviews and discussion forums
are more likely to be clicked. This example indicates that
the attractiveness of a search result is not only inﬂuenced
by its relevance but also determined by the user’s intrinsic
search intent behind the query.

WWW 2011 – Session: Intent UnderstandingMarch 28–April 1, 2011, Hyderabad, India17Intent

Intent Bias

Query

Click Probability

Relevance

Document

Figure 1: The triangular relationship among intent,
query and document. The edge connecting two en-
tities measures the degree of match between two en-
tities.

We design an experiment to validate that the relevance
between a query and a document is not a constant num-
ber. In the experiment, we collect search sessions, and par-
tition them into two groups according to diﬀerent search
intents. We note that after eliminating the position bias ef-
fect, most queries (96.6%) have signiﬁcantly diﬀerent click-
through rates on two intent groups. (Please refer to Section
3 for the experimental details.) In other words, the click-
through rate of an examined document varies greatly across
diﬀerent search sessions due to the diversity in search intent.
Figure 1 describes the triangular relationship among in-
tent, query and document, where the edge connecting the
two entities measures the degree of match between them.
Each user presumably has an intrinsic search intent before
submitting a query. When a user comes to a search engine,
she formulates a query according to her search intent and
submits it to the search engine. The intent bias measures
how well the query matches the intent, i.e., the degree of
match between the intent and the query. The search engine
receives the query and returns a list of ranked documents,
while the relevance measures the degree of match between a
query and a document. The user examines each document
and, if a document better satisﬁes her information need, she
is more likely to click this document.

The triangular relationship suggests that the user click is
determined by both intent bias and relevance. If a user does
not clearly express her information need in the input query,
there is a large intent bias. Thus, the user is unlikely to click
the document that does not meet her search intent, even if
the document is very relevant to the query. The examination
hypothesis can be considered as a simpliﬁed case, that it
regards the search intent and the input query as equivalent
and ignores the intent bias. Thus, the relevance between a
query and a document may be mistakenly estimated when
only the examination hypothesis is adopted.

In this paper, we incorporate the concepts of intent and
intent bias to propose a novel hypothesis, the intent hypoth-
esis, to explain how user clicks are aﬀected by intent bias,
relevance and position bias. The intent hypothesis can en-
hance the analytical power of the examination hypothesis,
characterize search intent diversity and interpret user clicks
better. Click models that adopt the intent hypothesis can
estimate more accurate and unbiased relevance.

This paper’s contributions are four-fold. First, we empir-
ically demonstrate the limitations of the examination hy-
pothesis and suggest that the position bias is not the only
bias aﬀecting click behavior. Second, we propose the novel
intent hypothesis to enhance the capability of modeling user
search behavior. Third, because the intent hypothesis is gen-
eral, we apply it to two typical click models, UBM and DBN,
and adopt a Bayesian inference method to model the intent
hypothesis. This inference method is capable of learning on

very large scale click-though logs. Finally, the experiment
has been conducted on 3.6 million queries and one billion
search sessions, and the results illustrate the advantages of
adopting the intent hypothesis.

This paper is organized as follows: In Section 2, we brieﬂy
review the previous research on click models including their
speciﬁcations and hypotheses. In section 3, we empirically
validate that the examination hypothesis can not well in-
terpret real click-through data.
In Section 4, we propose
our intent hypothesis and its inference method. In Section
5, the experiment on real datasets shows the advantages of
adopting the proposed hypothesis. In Section 6, we analyze
the intent bias that we estimated from the experiment and
discover some insightful results.

2. BACKGROUND

We start by introducing deﬁnitions and notations which
will be used throughout the paper. A user submits a query
q and the search engine returns a search result page contain-
ing M (usually M = 10) documents, denoted by {dπi}M
i=1,
where πi is the index of the document at the i-th position.
The user examines the summary of each search result and
clicks some or none of them. Here the summary includes the
search title, snippets and URL. A search session within the
same query is called a search session, denoted by s. Clicks
on sponsored ads and other web elements are not consid-
ered in one search session. We regard subsequent query re-
submission or re-formulation as a new session. The terms
url, document and result have the same meaning, and we
use them indiscriminately in the context.

We deﬁne three binary random variables, Ci, Ei and Ri to
model user click, user examination and document relevance
events at the i-th position:

• Ci: whether the user clicks on the result;
• Ei: whether the user examines the result;
• Ri: whether the document is relevant

where the ﬁrst event is observable from search sessions and
the last two events are hidden. Pr(Ci = 1) is the click-
through rate of the i-th document, Pr(Ei = 1) is the prob-
ability of examining the i-th document, and Pr(Ri = 1) is
the relevance of the i-th document. We use the parameter
rπi to represent the document relevance as

Pr(Ri = 1) = rπi

(1)

Next, we introduce the examination hypothesis mentioned
in Section 1. The examination hypothesis was originally pro-
posed by Richardson et al.
[16] and later formalized by
Craswell et al. [4]:

Hypothesis 1

(Examination Hypothesis). A document

is clicked if and only if it is both examined and relevant,
which can be formulated as

Ei = 1, Ri = 1 ⇔ Ci = 1

(2)

where Ri and Ei are independent of each other.

Equivalently, Formula (2) can be reformulated in a prob-

abilistic way:

Pr(Ci = 1|Ei = 1, Ri = 1) = 1
Pr(Ci = 1|Ei = 0) = 0
Pr(Ci = 1|Ri = 0) = 0

(3)
(4)
(5)

WWW 2011 – Session: Intent UnderstandingMarch 28–April 1, 2011, Hyderabad, India18After summation over Ri, this hypothesis can be simpliﬁed
as

Thus, as [16] explains, the document click-through rate is
represented by

Pr(Ci = 1) =

Pr(Ei = e) Pr(Ci = 1|Ei = e)

Pr(Ci = 1|Ei = 1) =r πi
Pr(Ci = 1|Ei = 0) = 0
(cid:2)
e∈{0,1}
(cid:3)
(cid:4)(cid:5)

(cid:4)(cid:5)

(cid:6)

= Pr(Ei = 1)

(cid:3)
(cid:6)
Pr(Ci = 1|Ei = 1)

(6)
(7)

position bias

document relevance

where the position bias and the document relevance are de-
composed. This hypothesis has been used in most of the
state-of-the-art click models to alleviate the position bias
problem. Next, we will brieﬂy review recent research on
click models in which DBN and UBM are used to imple-
ment the intent hypothesis in the paper.
2.1 Models Under Cascade Hypothesis

The cascade hypothesis was originally proposed by Craswell

et al. [4] to simulate the user search habit.

Hypothesis 2

(Cascade Hypothesis). A user exam-
ines search results from top to bottom without skips, and the
ﬁrst document is always examined:

Pr(E1 = 1) = 1
Pr(Ei+1 = 1|Ei = 0) = 0

(8)
(9)

The cascade model [4] combines the examination hypoth-
esis and the cascade hypothesis, and it further assumes that
the user stops the examination after reaching the ﬁrst click
and abandons the search session:

Pr(Ei+1 = 1|Ei = 1, Ci) = 1 − Ci

(10)

This model is too restrictive and can only deal with the
search sessions with at most one click.

The dependent click model (DCM) [9] generalizes the cas-
cade model to sessions with multiple clicks and introduces a
set of position-dependent parameters, i.e.,

Pr(Ei+1 = 1|Ei = 1, Ci = 1) =λ i
Pr(Ei+1 = 1|Ei = 1, Ci = 0) = 1

(11)
(12)

where λi represents the probability of examining the next
document after a click. These parameters are globally shared
across all search sessions. In this model, a user is simply as-
sumed to examine all the subsequent documents below the
position of the last click. In fact, if a user is satisﬁed with
the last clicked document, she usually does not continue ex-
amining the following results.

The dynamic Bayesian network model (DBN) [3] assumes
that document attractiveness determines the user click, and
the user satisfaction determines whether the user examines
the next document. Formally speaking,

Pr(Ei+1 = 1|Ei = 1, Ci = 1) =γ (1 − sπi )
Pr(Ei+1 = 1|Ei = 1, Ci = 0) =γ,

(13)
(14)

where the parameter γ is the probability the user examines
the next document without clicks, and the parameter sπi is
the user satisfaction. Experimental comparisons show that
DBN outperforms other click models based on the cascade

hypothesis. DBN employs the expectation maximization al-
gorithm to estimate parameters, which may require a great
number of iterations for convergence. Zhu et al. [19] intro-
duced a Bayesian inference method, expectation propagation
[14], for DBN.
2.2 User Browsing Model

The user browsing model (UBM) [6] is based on the exam-
ination hypothesis but does not follow the cascade hypoth-
esis. Instead, it assumes that the examination probability
Ei depends on the previous clicked position li = max{j ∈
{1, ··· , i − 1} |C j = 1} as well as the distance between the
i-th position and the li-th position:

Pr(Ei = 1|C1:i−1) = βli,i−li

(15)

If there are no clicks before the position i, li is set to 0. The
likelihood of a search session under UBM can be stated in a
quite simple form:

i=1

(rπi βli,i−li )Ci (1 − rπi βli,i−li )

Pr(C1:M ) =

(16)
where there are M (M +1)/2 {βi,j} parameters shared across
all search sessions. The Bayesian browsing model (BBM)
[13] follows the same assumptions of UBM but adopts a
Bayesian inference algorithm.

1−Ci

M(cid:7)

3. REVISITING EXAMINATION HYPOTH-

ESIS

As we mentioned above, the examination hypothesis is
the basis of most existing click models. The hypothesis is
mainly aimed at modeling the position bias in the click log
data.
In particular, it assumes that the probability of a
click’s occurrence is uniquely determined by the query and
the document after the document is examined by the user.
In this section, we use a controlled experiment to demon-
strate that the assumptions built into by the examination
hypothesis cannot completely interpret the click-through log.
We show that, given a query and an examined document,
there is still diversity among click-through rates on this doc-
ument. This phenomenon clearly suggests that the position
bias is not the only bias that aﬀects click behaviors.

In order to perform the experiment, we collected click-
through logs for one month in which each session contains
the top ten returned documents in the search result page.
We selected the search sessions that have at least one click
on the documents at positions 2 to 10. Since it is widely
believed that the user browses search results from top to
bottom, thus, from the fact that at least one of the docu-
ments at the last nine positions is clicked, we can assume
that the document at the ﬁrst position is always examined.
The search sessions are further divided into two groups with
respect to the number of clicks at the last nine positions:
one group includes sessions which have exactly one click at
the last nine positions, while another group includes sessions
which have at least two clicks at these positions. For each
search query, the click-through rate is calculated on the same
document and this document is at the ﬁrst position. We ran-
domly chose ﬁve queries and reported the click-through rate
values on two groups of sessions in Figure 2.

According to the examination hypothesis, the relevance
between a query and a document is a constant number, if

WWW 2011 – Session: Intent UnderstandingMarch 28–April 1, 2011, Hyderabad, India19 

1
n
o

i
t
i
s
o
p

 
t

a

 
t

n
e
m
u
c
o
d

 

e
h

t
 

n
o

 

t

e
a
r
 
h
g
u
o
r
h
−
k
c

t

i
l

C

(# clicks at position 2 to 10) = 1
(# clicks at position 2 to 10) > 1

0.6

0.5

0.4

0.3

0.2

0.1

0.0

vitamins

sudoku

hulu

pac man gpa calculator

Query

Figure 2: The document click-through rate values
on two groups of search sessions over ﬁve randomly
picked queries. One group includes sessions with
exactly one click at positions 2 to 10, and another
group includes sessions with at least two clicks at
positions 2 to 10. For each query, the click-through
rate is calculated on the same document and this
document is always at the ﬁrst position.

the document has been examined. It implies that the click-
through rate in the two groups should be equivalent to each
other, since the document at the top position is considered
always to be examined. As shown in Figure 2, however, none
of the queries presents the same click-through rate value on
the two groups. Instead, it is observed that the click-through
rate in the second group is signiﬁcantly higher than that
in the ﬁrst group since the P-values of t-test on these two
groups is much less than 1%.

In order to investigate the generalization of this analysis,
we subtract the click-through rate in the ﬁrst group from
that in the second group and plot the distribution of this
diﬀerence over all search queries. Figure 3 illustrates the
diﬀerence of the click-through rate values on two groups for
all queries. The resulting distribution matches a Gaussian
distribution whose center is at a positive point about 0.2.
Speciﬁcally, we found that the number of queries whose cor-
responding diﬀerence is located within [−0.01, 0.01] occupies
only 3.34% of all queries, which indicates that the examina-
tion hypothesis cannot precisely charaterize the click behav-
iors for most of the queries.

Since we believe that the users have not read the last
nine documents when they are browsing the ﬁrst document,
whether the ﬁrst document has a click is an independent
event to the click on the last nine documents. Thus, the only
possible explanation for the observed phenomenon is that
there is an intrinsic search intent behind the query and that
this intent leads to the click diversity in the two groups. In
Section 4, we will characterize this diversity by the concept
of search intent and propose the intent hypothesis for click
models.

4. MODELING INTENT DIVERSITY
4.1 Intent Hypothesis

We propose a new hypothesis called the intent hypothesis.
The intent hypothesis preserves the concept of examination
proposed by the examination hypothesis. Moreover, our hy-

y
t
i
s
n
e
D

0
3

.

5

.

2

0
2

.

5
1

.

0
1

.

5
0

.

0
0

.

−0.5

0.0

0.5

1.0

Difference of click−through rates

Figure 3: The distribution of the CTR diﬀerence on
two group search sessions.

pothesis assumes that a document is clicked only after it
meets the user’s search intent, i.e. it is needed by the user.
Since the query partially reﬂects the user’s search intent, it
is reasonable to assume that a document is never needed if
it is irrelevant to the query. On the other hand, whether a
relevant document is needed is uniquely inﬂuenced by the
gap between the user’s intent and the query. From this deﬁ-
nition, if we are sure that the user always submits the query
which exactly reﬂects her search intent, then the intent hy-
pothesis will be reduced to the examination hypothesis.

Formally, the intent hypothesis includes the following three

statements:

1. The user will click a document if and only if it is ex-

amined and needed by the user.

2. If a document is irrelevant, the user will not need it.
3. If a document is relevant, whether it is needed is only
inﬂuenced by the gap between the user’s intent and
the query.

Figure 4 compares the graphical models of the examina-
tion hypothesis and the intent hypothesis. We can see in
the intent hypothesis a latent event Ni is inserted between
Ri and Ci, in order to distinguish the occurrence of being
relevant and being clicked.

Hidden:

Ei

Ri

Hidden:

Ei

Observed:

Ci

Observed:

Ri

Ni

Ci

(a) Examination Hypothesis

(b) Intent Hypothesis

Figure 4: The graphical models of the examination
hypothesis and the intent hypothesis

It order to represent the intent hypothesis in a proba-
bilistic way, we ﬁrst introduce some symbols. Suppose that
there are m documents in the session s. The i-th document
is denoted by dπi and whether it is clicked is denoted by Ci.
Ci is a binary variable. Ci = 1 represents that the docu-
ment is clicked and Ci = 0 represents that it is not clicked.
Similarly, whether the document dπi is examined, whether

WWW 2011 – Session: Intent UnderstandingMarch 28–April 1, 2011, Hyderabad, India20it is relevant and whether it is needed are respectively rep-
resented by the binary variables Ei, Ri and Ni. Under this
deﬁnition, the intent hypothesis can be formulated as:

Ei = 1, Ni = 1 ⇔ Ci = 1

Pr(Ri = 1) =r πi
Pr(Ni = 1|Ri = 0) = 0
Pr(Ni = 1|Ri = 1) =μ s

(17)
(18)
(19)
(20)

Here, rπi is the relevance of the document dπi , and μs
is deﬁned as the intent bias. Since the intent hypothesis
assumes that μs should only be inﬂuenced by the intent and
the query, μs is shared across all documents in the same
session, which means that it is a global latent variable in
session s. However, in diﬀerent sessions, the intent bias is
supposed to be diﬀerent.

After we combine (17), (18), (19) and (20), it is not diﬃ-

cult to derive that:

Pr(Ci = 1|Ei = 1) =μ srπi
Pr(Ci = 1|Ei = 0) = 0

(21)
(22)

Compared to Equation (6) derived from the examination
hypothesis, Equation (21) adds a coeﬃcient μs to the orig-
inal relevance rπi . Intuitively, it can be seen that we take
a μs discount oﬀ the relevance. Especially, if the value of
μs is ﬁxed to 1, it means that there will be no intent bias
and that our hypothesis will degenerate into the examina-
tion hypothesis.
4.2 Click Model Implementations

For all previous click models based on the examination
hypothesis, the switch from the examination hypothesis to
the intent hypothesis is quite simple. Actually, we only need
to replace formula (6) with formula (21) without changing
any other speciﬁcations. Here, the latent intent bias μs is
local for each session s. Every session maintains its own
intent bias, and the intent biases for diﬀerent sessions are
mutually independent.
When the intent hypothesis is adopted to construct or
reconstruct a click model M, the resulting click model is
referred to as Unbiased-M.
In this paper, we choose two
state-of-the-art models, DBN and UBM, to illustrate the
impact of the intent hypothesis. The new models based on
DBN and UBM are called Unbiased-DBN and Unbiased-
UBM respectively.
4.3 Inference
4.3.1 Parameter Estimation
As speciﬁed above, when an unbiased model is constructed,
we estimate the value of μs for each session. After all of the
μs are known, then other parameters of the click model (such
as relevance) can be learned. However, since the estimation
of μs relies on learning the results of other parameters, the
entire inference process has deadlocks. To avoid this prob-
lem, we adopt an iterative inference as shown in Algorithm
1.

Every iteration consists of two phases.

In Phase A, we
learn the click model parameter Θ based on the estimated
values of μs of the last iteration. In Phase B, we estimate
the value of μs for each session based on the parameters Θ
learned in Phase A. Here, the likelihood function that we

Algorithm 1 Iterative inference of unbiased model
Require: Input a set S of sessions as training data and an
original click model M (Its own parameter set is denoted
by Θ.)
1: Initialize the intent bias μs ← 1 for each session s in S.
2: repeat
3:

Phase A: We learn every parameter in Θ using the
original inference method of M while we ﬁx the values
of μs according to the latest estimated values of μs.

4:

Phase B: We estimate the value of μs for each ses-
sion, using maximum-likelihood estimation, under the
learning result of parameters Θ generated in phase A.

5: until all parameters converge

want to maximize is the conditional probability that the ac-
tual click events of this session occur under the speciﬁcation
of the click model, with μs being treated as the condition.
Phase A and Phase B should be executed alternatively and
iteratively until all parameters converge.

This general inference framework can be modiﬁed to be
more eﬃcient if the parameters except μs could be learned
through online Bayesian inference. In this case, the inference
is still online even after the estimations of μs are included.
Speciﬁcally, when a session is loaded, we use the posterior
distributions learned from the previous sessions to give an
estimation for μs. We then use the estimated value of μs
to update the distribution of other parameters. Since the
distribution of every parameter changes little before and af-
ter the update, we do not need to reestimate the value of
μs anymore, so that no iterative steps are needed. Thus, af-
ter all the parameters are updated, we just load in the next
session and continue the learning process.

As described in Section 2, both UBM and DBN can em-
ploy the Bayesian Paradigm to infer the parameters. Ac-
cording to the method mentioned above, as a new session is
loaded for training, there are three steps to execute:

1. We integrate over all the parameters except μs to de-

rive the likelihood function Pr(C1:m|μs).

2. We maximize this likelihood function to estimate the

value of μs.

3. Fixing the value of μs, we update other parameters by

the Bayesian inference method.

Such online Bayesian inference facilitates the single-pass
and incremental computation, which is appealing for very
large-scale data processing.
4.3.2 Click Prediction
Given a test session, the joint probability distribution of
click events in this session can be calculated by the following
formula.

(cid:8) 1

Pr(C1:m) =

0

Pr(C1:m|μs)p(μs)d(μs)

(23)

In order to determine p(μs), we investigate the distribu-
tion of the estimated μs in the training process and draw
a density histogram of μs for each query. Then we use the
density histogram as an approximation to p(μs).
In our
implementation, we evenly divide the range [0, 1] into 100
segments and count the density of μs that fall into each of
the segments, and then we treat this density distribution as
p(μs).

WWW 2011 – Session: Intent UnderstandingMarch 28–April 1, 2011, Hyderabad, India21It is worth noting that our method is not able to predict
the exact value of the intent bias for future sessions. This is
because the intent bias can only be estimated when the ac-
tual user clicks are available, but in the testing data, the user
click is hidden and should be unknown to the click model.
Thus, we average the prediction result of future clicks over
all intent bias according to the distribution of the intent
bias counting from the training set. This averaging step
might lose the advantage of the intent hypothesis.
In an
extreme case that a query never occurs in the training data,
our model will set the intent bias to be 1, where the intent
hypothesis degenerates to the examination hypothesis and
gives the same prediction result as the original model.
4.4 An Example: User Browsing Model

We take the User Browsing Model (UBM) as an exam-
ple to demonstrate how to apply the intent hypothesis to a
click model. A Bayesian inference procedure to estimate the
parameters is also introduced.
4.4.1 Model
Given a search session s, UBM takes the document rele-
vances and transition probabilities as its parameters. As we
mentioned in Section 2, the parameters in a single session
can be denoted by Θ = {rπi}M
i=1. In addition,
if we want to apply the intent hypothesis to UBM, then a
new parameter should be maintained. This parameter is the
intent bias for session s, which we denote by μs. Under the
intent hypothesis, the revised version of the UBM model is
formulated by (21), (22) and (15).
likelihood Pr(s|Θ, μs) for session s as :
Pr(s|Θ, μs) (cid:2) Pr(C1:M|Θ, μs)
M(cid:7)

According to the above model speciﬁcation, we derive the

i=1 ∪{βli,i−li}M

1(cid:2)

(cid:9)

Pr(Ci | Ei = k, μs, rπi )·
Pr(Ei = k | C1:i−1, βli,i−li )

(cid:10)

(24)

i=1

k=0

=

=

M(cid:7)

i=1

(μsrπi βli,i−li )Ci (1 − μsrπi βli,i−li )

1−Ci

(25)

Here, Ci represents whether the document at position i is
clicked. The overall likelihood for the entire dataset is the
product of the likelihood for every single session.
4.4.2 Parameter Estimation
We adopt the Bayesian Paradigm to infer the parameters.
The learning process is incremental: we load and process
search sessions one by one, and the data for each session
is discarded after it has been processed in the Bayesian in-
ference. Given a new incoming session s, we update the
distribution of each parameter θ ∈ Θ based on the session
data and the click model. Before the update, each θ has a
prior distribution p(θ). We compute the likelihood function
P (s|θ) , multiply it to the prior distribution p(θ), and derive
the posterior distribution p(θ|s). Finally, the distribution of
θ is updated with respect to its posterior distribution.

Let’s examine this updating procedure in more detail.
First, we integrate the likelihood function (25) over Θ to
derive a marginal likelihood function only conditioned on
the intent bias:

(cid:8)

Pr(s|μs) =

p(Θ) Pr(s|Θ, μs)dΘ

R|Θ|

R|Θ(cid:2)|

Since Pr(s|μs) is a unimodal function, we can maximize
it by the ternary searching procedure on the parameter μs,
which is in the range of [0, 1]. The optimal value for μs is
∗
then denoted by μ
s.
of each parameter θ ∈ Θ via the Bayes’ Rule:
Pr(s|Θ, μs = μ
∗
s)p(Θ

With μs optimized, we derive the posterior distributions

s) ∝ p(θ)
p(θ|s, μs = μ
∗

)dΘ

(cid:8)

(cid:4)

(cid:4)

(cid:4)

= Θ\{θ} for short notation.

where Θ

The ﬁnal step is to update p(θ) according to p(θ|s, μs =
∗
μ
s). To make the whole inference process tractable, it is
usually necessary to restrict the mathematical form of p(θ)
to a speciﬁc distribution family. Here, we adopt the Probit
Bayesian Inference (PBI) proposed by Zhang et al. [18] to
implement the ﬁnal update. PBI connects each θ with an
auxiliary variable x through the probit link θ = Φ(x), and
restricts p(x) always to the Gaussian family. Thus, in order
to update p(θ), it is suﬃcient to derive p(x|μs = μ
∗
s) from
p(θ|μs = μ
∗
s ) and approximate it by a Gaussian density.
Then we use the approximation to update p(x) and further
update p(θ). For more details, please refer to [18].

Since the learning is incremental, the update procedure is

executed once for each session.

5. EXPERIMENTS

In this section, we test the intent hypothesis with two
state-of-the-art click models, DBN and UBM, and the orig-
inal examination hypothesis in DBN and UBM are replaced
by the intent hypothesis. We denote the new click mod-
els by Unbiased-UBM and Unbiased-DBN respectively. In
the experiment, we ﬁrstly use the estimated relevance from
click models to rank the documents and then evaluate the
ranking using the human labeled relevance with respect to
the normalized discounted cumulative gains (NDCG) [10].
Secondly, we use log-likelihood to evaluate how accurately
the Unbiased-UBM and Unbiased-DBN predict user future
clicks over UBM and DBN.
5.1 Experimental Setting
Training and testing datasets: The search sessions used
to train and evaluate click models were collected from a com-
mercial search engine in the U.S. market in the English lan-
guage in January 2010. A session consists of a input query,
a list of returned documents on the search result page and
a list of clicked positions. We collected the session subject
to the following constraints: (1) the search session is on the
ﬁrst result page returned by the search engine; (2) all clicks
in the session are on the search result but neither on spon-
sored ads nor on other web elements. In order to prevent the
whole dataset from becoming dominated by the extremely
frequent queries, we allow each query at most 106 sessions.
We also ﬁlter the search sessions to remove queries with low
frequency less than 101.5. For each query, we sort its search
sessions according to the time stamp when the query is sent
to the search engine and split them into the training and the
testing sets at a ratio of 3:1. In total, we collect approxi-
mately one billion sessions over 3.6 million distinct queries.
The detailed information about the dataset is summarized
in Table 1.
Human judgment relevance: The manually labeled data
is used as the ground truth for evaluating the relevance es-
timated from click models. The human relevance system

WWW 2011 – Session: Intent UnderstandingMarch 28–April 1, 2011, Hyderabad, India22Query Frequency # Query # Document # Session #HRS Query # HRS Ratings

101.5 to 102
102 to 102.5
102.5 to 103
103 to 103.5
103.5 to 104
104 to 104.5
104.5 to 105

> 105
Total

2,503,666
782,494
241,528
740,53
21,871
6,111
1,688
616

3,632,027

56,985,022
24,846,850
11,411,317
5,184,211
2,225,700
873,366
356,813
196,746

102,080,025

133,499,657
131,894,026
128,167,508
124,342,019
115,626,785
101,222,539
88,668,305
139,407,426
962,828,265

2,402
2,410
2,132
1,869
1,317
893
471
265

428,236
443,646
383,308
371,900
285,318
223,911
133,469
88,236

11,759

2,358,024

Table 1: The summary of the data set collected from one month of click logs.

Model

UBM

UBM

Unbiased-UBM
Improvement

DBN

DBN

Unbiased-DBN
Improvement

NDCG@1 NDCG@3 NDCG@5 NDCG@7 NDCG@10

0.578
0.660
14.14%
0.562
0.621
10.47%

0.577
0.628
8.90%
0.569
0.613
7.74%

0.587
0.632
7.71%
0.584
0.620
6.19%

0.606
0.648
6.94%
0.604
0.636
5.22%

0.596
0.633
6.25%
0.596
0.623
4.55%

Table 2: The experimental results on NDCG

(HRS) randomly picks a set of queries and requires editors
to label the relevance between these queries and their corre-
sponding search documents. For each query-document pair,
editors give ﬁve ratings ranging from 0 to 4, corresponding
to ﬁve scales: bad, fair, good, excellent, and perfect. HRS
rating for a query-document pair is derived by averaging
the ratings of this pair from several editors. On average,
200.53 documents for a query have HRS ratings. In total,
HRS generated 2 million ratings for our data set. The last
two columns in Table 1 show the summarized HRS rating
information.
5.2 Accuracy in Relevance Estimation

One important ability of the click model is to estimate
the document relevance. The trained click model is able
to provide the estimated relevance for each query-document
pair. We can rank all documents under a query according to
the estimated relevance and compare this predicted ranking
with the human judgment ranking. We expect the accuracy
of the relevance estimation can be improved after eliminat-
ing the eﬀect of the intent bias.

The normalized discounted cumulative gain (NDCG) [10]
is a well-known metric for measuring the divergence between
the predicted ranking and human judgments. NDCG is cal-
culated cumulatively from the top of the result list to the
bottom with the gain of each result discounted at lower
ranks. Higher NDCG values correspond to a better rank-
ing result. We report the arithmetic mean of NDCG over
multiple queries. Precisely, given a ranking, the integer se-
quence {gi} denotes the editorial relevances of the docu-
ments ordered by the ranking. The NDCG at a particular
rank threshold K is deﬁned as:

NDCG@K =

2gi − 1
log(1 + i)

K(cid:2)

1

Z@K

i=1

where Z@K is the normalization to make the ideal ranking
(i.e. the ranking obtained by ordering the documents ac-
cording to their editorial relevance) to have NDCG value of
1. We report NDCG over multiple queries using the arith-
metic mean. We use the relative NDCG improvement to

evaluate the model with the intent hypothesis and with the
examination hypothesis.

Unbiased−DBN upon DBN    
Unbiased−UBM upon UBM   

NDCG@3: 0.586 upon 0.514

NDCG@3: 0.602 upon 0.532

 

%
 
8
1

 

%
 
6
1

 

%
 
4
1

 

%
 
2
1

 

%
 
0
1

 

%
 
8

 

%
 
6

3
@
G
C
D
N

 
f
o
 
t
n
e
m
e
v
o
r
p
m

I

10^1.5

10^2

10^2.5

10^3

10^3.5

10^4

10^4.5

10^5

Infinity

Query Frequency

Figure 5: The relative NDCG improvement over
query frequencies

We list NDCG evaluation results for the whole dataset
in Table 2. It shows that NDCG@1 has been improved by
14.14% from 0.578 to 0.660 for UBM and 10.47% from 0.562
to 0.621 for DBN. NDCG@10 has been improved 6.25% for
UBM and 4.55% for DBN. We clearly see that the new click
models with the intent hypothesis outperform previous mod-
els with the examination hypothesis. The lower rank thresh-
old K is, the higher NDCG@K improvement rate achieved.
We perform the signiﬁcance test for the NDCG improve-
ments at all ten rank threshold K’s, and ﬁnd that the P-
values of t-test are all less than 0.01%. Therefore, we con-
clude that the NDCG improvement after adopting the intent
hypothesis is statistically signiﬁcant.

Furthermore, we investigate at which query frequency the
intent hypothesis contributes the greatest improvement. We

WWW 2011 – Session: Intent UnderstandingMarch 28–April 1, 2011, Hyderabad, India231

1.02

1.06

1.11

1.18

1.25

1.35

1.5

1.74

6.17

10

Unbiased−DBN upon DBN    
Unbiased−UBM upon UBM    

NDCG@3: 0.615 upon 0.528
NDCG@3: 0.600 upon 0.52

 

 

%
0
2

 

 

%
5
1

 

 

%
0
1

 

%
5

 

3
@
G
C
D
N

 
f

o

 
t

n
e
m
e
v
o
r
p
m

I

Unbiased−DBN upon DBN  
Unbiased−UBM upon UBM 

 

%
4

 

 

%
3

 

 

%
2

 

 

%
1

 

d
o
o
h

i
l

i

e
k
L
−
g
o
L

 
f

o

 
t

n
e
m
e
v
o
r
p
m

I

 

%
0

 

 

%
0

 

0 % 

10 % 

20 % 

30 % 

40 % 

50 % 

60 % 

70 % 

80 % 

90 %  100 % 

Percentage of queries ordered by the number of clicks per session

Figure 6: The relative NDCG improvement over av-
erage number of clicks

plot the relative NDCG@3 improvement across diﬀerent query
frequencies for UBM and DBN in Figure 5. We can see
the NDCG improvement is very consistent across all query
frequencies. Each of the curves approximately forms an in-
teresting unimodal pattern. In the beginning, as the query
frequency increases, the increase on NDCG improvement is
mainly because we can learn the intent bias more accurately
with the increase in data. After reaching the NDCG im-
provement peak at about 104, the relevance improvement
becomes less, since the relevance estimation from the base-
line model has become more accurate as more search sessions
are used for training. As we can see, the intent hypothesis
helps the baseline model with the examination hypothesis
improve the relevance estimation for most queries, especially
queries whose frequencies are between 103 to 104.

From the analysis in Section 3, we can see that the num-
ber of clicks within a search session is related to the intent
bias, and it is interesting to see the relevance improvement
on queries with diﬀerent numbers of clicks. Thus, for each
query, we calculate the average number of clicks over all ses-
sions. We split the query set into 10 equal subsets according
to the increasing order of the average number of clicks. We
plot the curves of the improvement rates of NDCG@3 for
these 10 subsets in Figure 6. The ten corresponding quan-
tiles of the average number of clicks are aligned along the
x-axis above the box. From the ﬁgure, we clearly see that
the curves also have a unimodal form. As we know, a query
with lower average number of clicks tends to be navigational,
while a query with higher average number of clicks tends to
be informational. In the beginning, along with the increase
of the average number of clicks, the intent hypothesis leads
to more signiﬁcant improvement. Thus, the intent hypoth-
esis makes the click model to more accurately characterize
informational queries, which usually have the diversity of
search intents. If the average number of clicks become large
enough, the user’s intrinsic intents will become too ambigu-
ous to be characterized by the intent bias. Thus, after a
peak point where there is already quite large average num-
ber of clicks, the improvement will start to drop with the
increase in the average number of clicks.

10^1.5

10^2

10^2.5

10^3

10^3.5

10^4

10^4.5

10^5

Infinity

Query Frequency

Figure 7: The Log-likelihood improvement over
query frequencies
5.3 Accuracy in Click Prediction

After training the model, the parameters in click model
have been estimated and we can use it to predict the joint
probabilities Pr(C1:m) for all click conﬁgurations. We eval-
uate the click prediction by log-likelihood (LL), which has
been widely used to measure the ﬁtness in click models such
as UBM [6] and CCM [8]. Its value indicates the logarithm
of the joint probability of user click events in testing datasets
predicted by the trained click model. A larger LL indi-
cates better prediction accuracy, and the optimal value is
0. The improvement of LL value (cid:7)1 over (cid:7)2 is computed
as (exp((cid:7)1 − (cid:7)2) − 1) × 100%. We report average LL over
multiple sessions using arithmetic mean.

Figure 7 demonstrates the relative log-likelihood improve-
ments on Unbiased-UBM and Unbiased-DBN over UBM and
DBN on diﬀerent query frequencies. For frequent queries,
the baseline model can also accurately predict clicks. So the
improvement curves drop along query frequencies. The over-
all improvements in log-likelihood are 2.10% for DBN and
2.96% for UBM. We can see that the performance of our
new models on log-likelihood is close to the baseline model.
As introduced in Section 4.3.2, the prediction results are
the average of cases over all intent biases according to the
distribution of intent bias computed from the training set.

6. DISCUSSION

In this section, we report several interesting ﬁndings asso-
ciated with the concept of intent bias. Our study suggests
that the calculation of intent bias is not only helpful in es-
timating the unbiased document relevance but also allows
us to investigate more deeply some other web search mech-
anisms.
6.1 Intent Bias Distribution

We discovered that the sessions of informational queries
and navigational queries have signiﬁcantly diﬀerent intent
bias distributions. This property allows us to design an au-
tomatic method for classifying queries into two classes —
informational and navigational.

Let us start with two examples.

In Figure 8(a), we re-
port the density distribution of intent bias for the query

WWW 2011 – Session: Intent UnderstandingMarch 28–April 1, 2011, Hyderabad, India24“photosynthesis” in a density histogram. In this histogram,
the density distribution is multi-modal, which means that
the search pattern of all users can be clustered into several
groups, each with an intent bias. This observation coincides
with our intuition that in an informational query such as
“photosynthesis”, it is hard to reﬂect the exact search in-
tent of every user. However, since a density near 1 is larger
than the density at other values, we can conclude that the
majority of users tends to click on the documents which are
relevant. In Figure 8(b), we report the density distribution
of intent bias for the query “paypal”, which is a typical nav-
igational query. Diﬀerent from the informational query, in
this case the sessions with an intent bias near 1 dominate all
the sessions. This result is also intuitive, because we believe
that a navigational query is much more likely to precisely
reﬂect the user’s intent than an informational query.

y
t
i
s
n
e
D

.

0
1

.

8
0

.

6
0

4
0

.

.

2
0

0
0

.

Navigational Query  
Informational Query  

0
1

8

y
t
i
s
n
e
D

6

4

2

0

0
2

5
1

y
t
i
s
n
e
D

0
1

5

0

0.0

0.2

0.4
0.6
Intent Bias

0.8

1.0

0.0

0.2

0.4
0.6
Intent Bias

0.8

1.0

(a) query “photosynthesis”

(b) query “paypal”

Figure 8: Density histogram of intent bias on the
two example queries

In order to numerically characterize the diﬀerence between
the distributions of Figure 8(a) and Figure 8(b), we cal-
culate the entropy of the intent bias distribution for each
query. The entropy measures the degree of the diversity of
the intent biases behind a single query: a higher entropy
value suggests that the distribution of intent biases is more
diversiﬁed, while a lower entropy value suggests that the dis-
tribution is more concentrated. Obviously, the entropy for
the query “photosynthesis” (2.4611) is higher than that for
“paypal” (0.1452).

To give a more convincing conclusion, we manually chose
200 informational queries and 200 navigational queries, and
plotted the distribution of entropies on these two classes
of queries in Figure 9. It is observed that the entropy for
navigational queries is mostly located near zero, while the
entropy for informational queries are distributed around a
positive value far away from zero. This observation exactly
coincides with our intuition that there is a larger degree of
diversity in intent biases for informational queries.

The above analysis suggests that search engines can main-
tain a query classiﬁer based on the entropy of the intent bias.
With such a classiﬁer, the search engine can treat queries
with a single intent and with multiple intents diﬀerently so
as to satisfy the user’s information need behind the query.
6.2 Relationship between Intent Bias and Other

Click Patterns

According to the intent hypothesis, the intent bias of a

search session is deterministically derived from the click events.
Thus, there should be some speciﬁc connections between the
intent bias and other click patterns, such as the click posi-
tions and the number of clicks. In Figure 10, we report the

0

1

2

3

4

Entropy of intent bias distribution

Figure 9: The distribution of the entropy of the in-
tent bias over the two groups of queries, i.e., the
informational queries and the navigational queries.

relation between intent bias and three statistical quantities,
including the ﬁrst-click position, the last-click position and
the number of clicks in the session. These quantities are av-
eraged among all the search sessions based on three months
of data. In order to avoid the misapprehension, it is neces-
sary to note that the higher value of μ, which is listed along
the x-axis, means the lower intent bias. For example, the
rightmost endpoint of x-axis corresponds the case that there
is no intent bias.

As illustrated in Figure 10, the ﬁrst-click position de-
creases as the value of μ increases. This phenomenon is
natural, since the lower the intent bias becomes, the more
similarity there is between the user’s search intent and the
query she issues. Since the search engine arranges the po-
sition of documents with respect to their similarities to the
query, a higher positioned document is more likely to have
a close connection to the query, and a higher probability of
being clicked by the user.
On the other hand, Figure 10 shows that the last-click
position decreases in the range of [0, 0.4) ∪ (0.85, 1] and in-
creases in the range of [0.4, 0.85]. The reason for its increase
may be due to another characteristic of the search intent:
with a high intent bias, the user tends to continue browsing
the search result page and click more documents. However,
why does the last-click position dramatically decrease in the
range of (0.85, 1]? This phenomenon is caused by the ex-
istence of navigational queries.
In fact, users who submit
navigational queries usually have their intent biases close to
zero, or value of μ close to 1. Most of them would be sat-
isﬁed by the top document and leave. Thus, the last-click
position in sessions with a low intent bias is often equal to
the ﬁrst-click position.

The curve of the average number of clicks can also be in-
terpreted in a similar way. For intent biases in the range
of [0, 0.85), most of the queries are informational, so the
users click more documents if they have higher intent bi-
ases. However, for intent biases in the range of [0.85, 1], the
navigational queries occupy a large proportion, which makes
the average number of clicks close to 1.

The interesting connection between the intent bias and
other click features makes it a valuable attribute for the

WWW 2011 – Session: Intent UnderstandingMarch 28–April 1, 2011, Hyderabad, India25l

e
u
a
V

0
1

9

8

7

6

5

4

3

2

1

0

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Intent bias

Figure 10: The relation between the intent bias and
three click patterns such as the average ﬁrst click
position, the average last click position and the av-
erage number of clicks.

training of ranking functions.
In addition, it can also be
used for the recognition and classiﬁcation of click patterns.

7. CONCLUSION

In this paper, we have investigated the relationship be-
tween intent, document and query and make a deep explo-
ration of the gap between click-through rate and document
relevance. We have found that the widely adopted concepts
of the position bias and the examination hypothesis fail to
completely explain the actual bias between click-through
rate and relevance because of the gap between user search
intent and input query. In order to characterize the diversity
of search intent, we propose the intent hypothesis as a com-
plement to the original examination hypothesis. The new
hypothesis is very general and can be ﬁt into most of the
existing click models to improve their capacities for learn-
ing unbiased relevance. Under the concept of intent bias
introduced in this paper, we have successfully modeled the
actual bias between click-through rate and relevance, whose
rationality has been veriﬁed both theoretically and empiri-
cally. Furthermore, we have demonstrated how to infer the
click models with the consideration of the intent hypothesis.
The experiments on large scale click through log show that
the models with the intent hypothesis consistently and sig-
niﬁcantly perform better than the original versions of click
model under the examination hypothesis.

Besides user clicks, other useful information can be de-
rived from in click through logs, such as the user’s history of
input queries and visited pages. This kind of information is
related to the user’s current search intent and can be used
to better identify the search intent behind the query. Our
next step is to include such information into the click model
with the intent hypothesis to further improve click model
accuracy.
Acknowledgment
Botao Hu would like to thank Prof. Roger Olesen of Ts-
inghua University for polishing the language. Botao Hu was
supported in part by the National Basic Research Program

Average first click position 
Average last click position 
Average number of clicks

of China Grant 2007CB807900, 2007CB807901, the National
Natural Science Foundation of China Grant 60604033, 60553001,
61073174, 61033001 and the Hi-Tech research and Develop-
ment Program of China Grant 2006AA10Z216.

8. REFERENCES
[1] E. Agichtein, E. Brill, and S. Dumais. Improving web

search ranking by incorporating user behavior
information. SIGIR ’06, pages 19–26.

[2] A. Broder. A taxonomy of web search. SIGIR Forum,

36:3–10, September.

[3] O. Chapelle and Y. Zhang. A dynamic bayesian

network click model for web search ranking. WWW
’09, pages 1–10.

[4] N. Craswell, O. Zoeter, M. Taylor, and B. Ramsey. An
experimental comparison of click position-bias models.
WSDM ’08, pages 87–94.

[5] G. Dupret and C. Liao. A model to estimate intrinsic

document relevance from the clickthrough logs of a
web search engine. WSDM ’10, pages 181–190.

[6] G. E. Dupret and B. Piwowarski. A user browsing

model to predict search engine click data from past
observations. SIGIR ’08, pages 331–338.

[7] L. A. Granka, T. Joachims, and G. Gay. Eye-tracking

analysis of user behavior in www search. SIGIR ’04,
pages 478–479.

[8] F. Guo, C. Liu, A. Kannan, T. Minka, M. Taylor,

Y.-M. Wang, and C. Faloutsos. Click chain model in
web search. WWW ’09, pages 11–20.

[9] F. Guo, C. Liu, and Y. M. Wang. Eﬃcient

multiple-click models in web search. WSDM ’09, pages
124–131.

[10] K. J¨arvelin and J. Kek¨al¨ainen. Cumulated gain-based

evaluation of ir techniques. ACM Trans. Inf. Syst.,
20:422–446, October.

[11] T. Joachims. Optimizing search engines using

clickthrough data. KDD ’02, pages 133–142.

[12] T. Joachims, L. Granka, B. Pan, H. Hembrooke, and
G. Gay. Accurately interpreting clickthrough data as
implicit feedback. SIGIR ’05, pages 154–161.

[13] C. Liu, F. Guo, and C. Faloutsos. Bbm: bayesian

browsing model from petabyte-scale data. KDD ’09,
pages 537–546.

[14] T. P. Minka. Expectation propagation for approximate

bayesian inference. UAI ’01, pages 362–369.

[15] B. Piwowarski, G. Dupret, and R. Jones. Mining user
web search activity with layered bayesian networks or
how to capture a click in its context. WSDM ’2009,
pages 162–171.

[16] M. Richardson, E. Dominowska, and R. Ragno.

Predicting clicks: estimating the click-through rate for
new ads. WWW ’07, pages 521–530.

[17] R. Srikant, S. Basu, N. Wang, and D. Pregibon. User

browsing models: Relevance versus examination. KDD
’10, pages 223–232.

[18] Y. Zhang, D. Wang, G. Wang, W. Chen, Z. Zhang,

B. Hu, and L. Zhang. Learning click models via probit
bayesian inference. CIKM ’10, pages 439–448.

[19] Z. A. Zhu, W. Chen, T. Minka, C. Zhu, and Z. Chen.

A novel click model and its applications to online
advertising. WSDM ’10, pages 321–330.

WWW 2011 – Session: Intent UnderstandingMarch 28–April 1, 2011, Hyderabad, India26